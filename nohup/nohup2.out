mkdir: cannot create directory ‘data/market/all_imgs’: File exists
Market dataset loaded
  subset   | # ids | # images
  ---------------------------
  train    |   502 |     3291
  query    |   450 |     2057
  gallery  |   929 |    28788
  camstyle  |     0 |        0
=> Loaded checkpoint 'logs/market-ide/checkpoint.pth.tar'
=> Start epoch 50 
Test:
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:49: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(self.feat.weight, mode='fan_out')
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:50: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:51: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.weight, 1)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:52: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(self.classifier.weight, std=0.001)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:61: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.classifier.bias, 0)
Extract Features: [1/17]	Time 3.630 (3.630)	Data 1.502 (1.502)	
Extract Features: [2/17]	Time 0.267 (1.949)	Data 0.000 (0.751)	
Extract Features: [3/17]	Time 0.266 (1.388)	Data 0.000 (0.501)	
Extract Features: [4/17]	Time 0.266 (1.107)	Data 0.000 (0.376)	
Extract Features: [5/17]	Time 0.263 (0.938)	Data 0.000 (0.300)	
Extract Features: [6/17]	Time 0.266 (0.826)	Data 0.000 (0.250)	
Extract Features: [7/17]	Time 0.264 (0.746)	Data 0.000 (0.215)	
Extract Features: [8/17]	Time 0.266 (0.686)	Data 0.000 (0.188)	
Extract Features: [9/17]	Time 0.263 (0.639)	Data 0.000 (0.167)	
Extract Features: [10/17]	Time 0.263 (0.602)	Data 0.000 (0.150)	
Extract Features: [11/17]	Time 0.263 (0.571)	Data 0.000 (0.137)	
Extract Features: [12/17]	Time 0.264 (0.545)	Data 0.000 (0.125)	
Extract Features: [13/17]	Time 0.266 (0.524)	Data 0.000 (0.116)	
Extract Features: [14/17]	Time 0.261 (0.505)	Data 0.000 (0.107)	
Extract Features: [15/17]	Time 0.263 (0.489)	Data 0.000 (0.100)	
Extract Features: [16/17]	Time 0.262 (0.475)	Data 0.000 (0.094)	
Extract Features: [17/17]	Time 0.537 (0.478)	Data 0.000 (0.088)	
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs = Variable(inputs, volatile=True)
Extract Features: [1/225]	Time 0.992 (0.992)	Data 0.728 (0.728)	
Extract Features: [2/225]	Time 0.457 (0.724)	Data 0.191 (0.460)	
Extract Features: [3/225]	Time 0.274 (0.574)	Data 0.000 (0.307)	
Extract Features: [4/225]	Time 0.267 (0.497)	Data 0.001 (0.230)	
Extract Features: [5/225]	Time 0.290 (0.456)	Data 0.012 (0.187)	
Extract Features: [6/225]	Time 0.279 (0.426)	Data 0.003 (0.156)	
Extract Features: [7/225]	Time 0.282 (0.406)	Data 0.001 (0.134)	
Extract Features: [8/225]	Time 0.280 (0.390)	Data 0.000 (0.117)	
Extract Features: [9/225]	Time 0.280 (0.378)	Data 0.001 (0.104)	
Extract Features: [10/225]	Time 0.279 (0.368)	Data 0.001 (0.094)	
Extract Features: [11/225]	Time 0.281 (0.360)	Data 0.001 (0.085)	
Extract Features: [12/225]	Time 0.280 (0.353)	Data 0.002 (0.078)	
Extract Features: [13/225]	Time 0.279 (0.348)	Data 0.001 (0.072)	
Extract Features: [14/225]	Time 0.282 (0.343)	Data 0.005 (0.068)	
Extract Features: [15/225]	Time 0.278 (0.339)	Data 0.000 (0.063)	
Extract Features: [16/225]	Time 0.270 (0.334)	Data 0.001 (0.059)	
Extract Features: [17/225]	Time 0.269 (0.330)	Data 0.000 (0.056)	
Extract Features: [18/225]	Time 0.273 (0.327)	Data 0.000 (0.053)	
Extract Features: [19/225]	Time 0.275 (0.325)	Data 0.000 (0.050)	
Extract Features: [20/225]	Time 0.294 (0.323)	Data 0.016 (0.048)	
Extract Features: [21/225]	Time 0.272 (0.321)	Data 0.006 (0.046)	
Extract Features: [22/225]	Time 0.279 (0.319)	Data 0.002 (0.044)	
Extract Features: [23/225]	Time 0.273 (0.317)	Data 0.000 (0.042)	
Extract Features: [24/225]	Time 0.271 (0.315)	Data 0.001 (0.041)	
Extract Features: [25/225]	Time 0.265 (0.313)	Data 0.000 (0.039)	
Extract Features: [26/225]	Time 0.282 (0.312)	Data 0.000 (0.037)	
Extract Features: [27/225]	Time 0.279 (0.310)	Data 0.001 (0.036)	
Extract Features: [28/225]	Time 0.276 (0.309)	Data 0.001 (0.035)	
Extract Features: [29/225]	Time 0.280 (0.308)	Data 0.001 (0.034)	
Extract Features: [30/225]	Time 0.274 (0.307)	Data 0.000 (0.033)	
Extract Features: [31/225]	Time 0.279 (0.306)	Data 0.000 (0.031)	
Extract Features: [32/225]	Time 0.281 (0.305)	Data 0.006 (0.031)	
Extract Features: [33/225]	Time 0.276 (0.304)	Data 0.001 (0.030)	
Extract Features: [34/225]	Time 0.281 (0.304)	Data 0.001 (0.029)	
Extract Features: [35/225]	Time 0.280 (0.303)	Data 0.001 (0.028)	
Extract Features: [36/225]	Time 0.281 (0.302)	Data 0.001 (0.027)	
Extract Features: [37/225]	Time 0.282 (0.302)	Data 0.001 (0.027)	
Extract Features: [38/225]	Time 0.279 (0.301)	Data 0.000 (0.026)	
Extract Features: [39/225]	Time 0.281 (0.301)	Data 0.001 (0.025)	
Extract Features: [40/225]	Time 0.280 (0.300)	Data 0.000 (0.025)	
Extract Features: [41/225]	Time 0.279 (0.300)	Data 0.000 (0.024)	
Extract Features: [42/225]	Time 0.281 (0.299)	Data 0.005 (0.024)	
Extract Features: [43/225]	Time 0.272 (0.299)	Data 0.001 (0.023)	
Extract Features: [44/225]	Time 0.279 (0.298)	Data 0.000 (0.023)	
Extract Features: [45/225]	Time 0.284 (0.298)	Data 0.019 (0.022)	
Extract Features: [46/225]	Time 0.317 (0.298)	Data 0.020 (0.022)	
Extract Features: [47/225]	Time 0.266 (0.298)	Data 0.000 (0.022)	
Extract Features: [48/225]	Time 0.321 (0.298)	Data 0.043 (0.022)	
Extract Features: [49/225]	Time 0.282 (0.298)	Data 0.001 (0.022)	
Extract Features: [50/225]	Time 0.281 (0.297)	Data 0.000 (0.022)	
Extract Features: [51/225]	Time 0.272 (0.297)	Data 0.000 (0.021)	
Extract Features: [52/225]	Time 0.269 (0.296)	Data 0.000 (0.021)	
Extract Features: [53/225]	Time 0.278 (0.296)	Data 0.000 (0.020)	
Extract Features: [54/225]	Time 0.273 (0.296)	Data 0.002 (0.020)	
Extract Features: [55/225]	Time 0.277 (0.295)	Data 0.000 (0.020)	
Extract Features: [56/225]	Time 0.275 (0.295)	Data 0.000 (0.019)	
Extract Features: [57/225]	Time 0.275 (0.295)	Data 0.000 (0.019)	
Extract Features: [58/225]	Time 0.280 (0.294)	Data 0.000 (0.019)	
Extract Features: [59/225]	Time 0.280 (0.294)	Data 0.000 (0.018)	
Extract Features: [60/225]	Time 0.296 (0.294)	Data 0.013 (0.018)	
Extract Features: [61/225]	Time 0.281 (0.294)	Data 0.000 (0.018)	
Extract Features: [62/225]	Time 0.271 (0.294)	Data 0.000 (0.018)	
Extract Features: [63/225]	Time 0.273 (0.293)	Data 0.000 (0.017)	
Extract Features: [64/225]	Time 0.275 (0.293)	Data 0.001 (0.017)	
Extract Features: [65/225]	Time 0.279 (0.293)	Data 0.000 (0.017)	
Extract Features: [66/225]	Time 0.281 (0.293)	Data 0.000 (0.017)	
Extract Features: [67/225]	Time 0.274 (0.292)	Data 0.000 (0.016)	
Extract Features: [68/225]	Time 0.275 (0.292)	Data 0.000 (0.016)	
Extract Features: [69/225]	Time 0.268 (0.292)	Data 0.001 (0.016)	
Extract Features: [70/225]	Time 0.284 (0.292)	Data 0.006 (0.016)	
Extract Features: [71/225]	Time 0.279 (0.291)	Data 0.000 (0.016)	
Extract Features: [72/225]	Time 0.278 (0.291)	Data 0.009 (0.015)	
Extract Features: [73/225]	Time 0.283 (0.291)	Data 0.000 (0.015)	
Extract Features: [74/225]	Time 0.280 (0.291)	Data 0.000 (0.015)	
Extract Features: [75/225]	Time 0.277 (0.291)	Data 0.000 (0.015)	
Extract Features: [76/225]	Time 0.277 (0.291)	Data 0.002 (0.015)	
Extract Features: [77/225]	Time 0.268 (0.290)	Data 0.002 (0.015)	
Extract Features: [78/225]	Time 0.280 (0.290)	Data 0.003 (0.014)	
Extract Features: [79/225]	Time 0.280 (0.290)	Data 0.000 (0.014)	
Extract Features: [80/225]	Time 0.278 (0.290)	Data 0.000 (0.014)	
Extract Features: [81/225]	Time 0.274 (0.290)	Data 0.000 (0.014)	
Extract Features: [82/225]	Time 0.286 (0.290)	Data 0.005 (0.014)	
Extract Features: [83/225]	Time 0.281 (0.290)	Data 0.001 (0.014)	
Extract Features: [84/225]	Time 0.290 (0.290)	Data 0.011 (0.014)	
Extract Features: [85/225]	Time 0.279 (0.289)	Data 0.000 (0.013)	
Extract Features: [86/225]	Time 0.274 (0.289)	Data 0.000 (0.013)	
Extract Features: [87/225]	Time 0.271 (0.289)	Data 0.000 (0.013)	
Extract Features: [88/225]	Time 0.274 (0.289)	Data 0.000 (0.013)	
Extract Features: [89/225]	Time 0.281 (0.289)	Data 0.001 (0.013)	
Extract Features: [90/225]	Time 0.277 (0.289)	Data 0.000 (0.013)	
Extract Features: [91/225]	Time 0.274 (0.288)	Data 0.000 (0.013)	
Extract Features: [92/225]	Time 0.266 (0.288)	Data 0.000 (0.012)	
Extract Features: [93/225]	Time 0.282 (0.288)	Data 0.000 (0.012)	
Extract Features: [94/225]	Time 0.278 (0.288)	Data 0.001 (0.012)	
Extract Features: [95/225]	Time 0.274 (0.288)	Data 0.000 (0.012)	
Extract Features: [96/225]	Time 0.280 (0.288)	Data 0.002 (0.012)	
Extract Features: [97/225]	Time 0.274 (0.288)	Data 0.000 (0.012)	
Extract Features: [98/225]	Time 0.284 (0.288)	Data 0.001 (0.012)	
Extract Features: [99/225]	Time 0.272 (0.287)	Data 0.000 (0.012)	
Extract Features: [100/225]	Time 0.272 (0.287)	Data 0.000 (0.011)	
Extract Features: [101/225]	Time 0.271 (0.287)	Data 0.000 (0.011)	
Extract Features: [102/225]	Time 0.276 (0.287)	Data 0.000 (0.011)	
Extract Features: [103/225]	Time 0.266 (0.287)	Data 0.000 (0.011)	
Extract Features: [104/225]	Time 0.281 (0.287)	Data 0.001 (0.011)	
Extract Features: [105/225]	Time 0.303 (0.287)	Data 0.013 (0.011)	
Extract Features: [106/225]	Time 0.278 (0.287)	Data 0.001 (0.011)	
Extract Features: [107/225]	Time 0.269 (0.287)	Data 0.001 (0.011)	
Extract Features: [108/225]	Time 0.287 (0.287)	Data 0.000 (0.011)	
Extract Features: [109/225]	Time 0.286 (0.287)	Data 0.017 (0.011)	
Extract Features: [110/225]	Time 0.274 (0.287)	Data 0.000 (0.011)	
Extract Features: [111/225]	Time 0.285 (0.287)	Data 0.006 (0.011)	
Extract Features: [112/225]	Time 0.267 (0.286)	Data 0.000 (0.011)	
Extract Features: [113/225]	Time 0.273 (0.286)	Data 0.000 (0.011)	
Extract Features: [114/225]	Time 0.268 (0.286)	Data 0.000 (0.010)	
Extract Features: [115/225]	Time 0.272 (0.286)	Data 0.001 (0.010)	
Extract Features: [116/225]	Time 0.268 (0.286)	Data 0.000 (0.010)	
Extract Features: [117/225]	Time 0.265 (0.286)	Data 0.000 (0.010)	
Extract Features: [118/225]	Time 0.278 (0.286)	Data 0.001 (0.010)	
Extract Features: [119/225]	Time 0.278 (0.286)	Data 0.000 (0.010)	
Extract Features: [120/225]	Time 0.268 (0.285)	Data 0.000 (0.010)	
Extract Features: [121/225]	Time 0.281 (0.285)	Data 0.002 (0.010)	
Extract Features: [122/225]	Time 0.274 (0.285)	Data 0.001 (0.010)	
Extract Features: [123/225]	Time 0.278 (0.285)	Data 0.000 (0.010)	
Extract Features: [124/225]	Time 0.283 (0.285)	Data 0.001 (0.010)	/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:66: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  dist.addmm_(1, -2, x, y.t())

Extract Features: [125/225]	Time 0.281 (0.285)	Data 0.000 (0.010)	
Extract Features: [126/225]	Time 0.278 (0.285)	Data 0.000 (0.009)	
Extract Features: [127/225]	Time 0.280 (0.285)	Data 0.000 (0.009)	
Extract Features: [128/225]	Time 0.286 (0.285)	Data 0.000 (0.009)	
Extract Features: [129/225]	Time 0.268 (0.285)	Data 0.000 (0.009)	
Extract Features: [130/225]	Time 0.266 (0.285)	Data 0.000 (0.009)	
Extract Features: [131/225]	Time 0.277 (0.285)	Data 0.001 (0.009)	
Extract Features: [132/225]	Time 0.278 (0.285)	Data 0.001 (0.009)	
Extract Features: [133/225]	Time 0.277 (0.285)	Data 0.000 (0.009)	
Extract Features: [134/225]	Time 0.278 (0.285)	Data 0.000 (0.009)	
Extract Features: [135/225]	Time 0.280 (0.285)	Data 0.001 (0.009)	
Extract Features: [136/225]	Time 0.279 (0.284)	Data 0.000 (0.009)	
Extract Features: [137/225]	Time 0.265 (0.284)	Data 0.000 (0.009)	
Extract Features: [138/225]	Time 0.274 (0.284)	Data 0.001 (0.009)	
Extract Features: [139/225]	Time 0.272 (0.284)	Data 0.000 (0.009)	
Extract Features: [140/225]	Time 0.272 (0.284)	Data 0.000 (0.009)	
Extract Features: [141/225]	Time 0.282 (0.284)	Data 0.000 (0.009)	
Extract Features: [142/225]	Time 0.281 (0.284)	Data 0.000 (0.008)	
Extract Features: [143/225]	Time 0.274 (0.284)	Data 0.001 (0.008)	
Extract Features: [144/225]	Time 0.278 (0.284)	Data 0.000 (0.008)	
Extract Features: [145/225]	Time 0.282 (0.284)	Data 0.000 (0.008)	
Extract Features: [146/225]	Time 0.278 (0.284)	Data 0.000 (0.008)	
Extract Features: [147/225]	Time 0.281 (0.284)	Data 0.000 (0.008)	
Extract Features: [148/225]	Time 0.279 (0.284)	Data 0.001 (0.008)	
Extract Features: [149/225]	Time 0.279 (0.284)	Data 0.001 (0.008)	
Extract Features: [150/225]	Time 0.282 (0.284)	Data 0.001 (0.008)	
Extract Features: [151/225]	Time 0.279 (0.284)	Data 0.001 (0.008)	
Extract Features: [152/225]	Time 0.280 (0.284)	Data 0.000 (0.008)	
Extract Features: [153/225]	Time 0.268 (0.284)	Data 0.000 (0.008)	
Extract Features: [154/225]	Time 0.268 (0.284)	Data 0.000 (0.008)	
Extract Features: [155/225]	Time 0.282 (0.284)	Data 0.001 (0.008)	
Extract Features: [156/225]	Time 0.282 (0.284)	Data 0.001 (0.008)	
Extract Features: [157/225]	Time 0.280 (0.284)	Data 0.000 (0.008)	
Extract Features: [158/225]	Time 0.275 (0.283)	Data 0.001 (0.008)	
Extract Features: [159/225]	Time 0.281 (0.283)	Data 0.000 (0.008)	
Extract Features: [160/225]	Time 0.281 (0.283)	Data 0.000 (0.008)	
Extract Features: [161/225]	Time 0.267 (0.283)	Data 0.000 (0.008)	
Extract Features: [162/225]	Time 0.277 (0.283)	Data 0.000 (0.007)	
Extract Features: [163/225]	Time 0.279 (0.283)	Data 0.000 (0.007)	
Extract Features: [164/225]	Time 0.282 (0.283)	Data 0.001 (0.007)	
Extract Features: [165/225]	Time 0.279 (0.283)	Data 0.000 (0.007)	
Extract Features: [166/225]	Time 0.280 (0.283)	Data 0.001 (0.007)	
Extract Features: [167/225]	Time 0.280 (0.283)	Data 0.001 (0.007)	
Extract Features: [168/225]	Time 0.281 (0.283)	Data 0.003 (0.007)	
Extract Features: [169/225]	Time 0.280 (0.283)	Data 0.000 (0.007)	
Extract Features: [170/225]	Time 0.274 (0.283)	Data 0.000 (0.007)	
Extract Features: [171/225]	Time 0.287 (0.283)	Data 0.000 (0.007)	
Extract Features: [172/225]	Time 0.279 (0.283)	Data 0.001 (0.007)	
Extract Features: [173/225]	Time 0.280 (0.283)	Data 0.000 (0.007)	
Extract Features: [174/225]	Time 0.274 (0.283)	Data 0.000 (0.007)	
Extract Features: [175/225]	Time 0.276 (0.283)	Data 0.000 (0.007)	
Extract Features: [176/225]	Time 0.287 (0.283)	Data 0.004 (0.007)	
Extract Features: [177/225]	Time 0.277 (0.283)	Data 0.000 (0.007)	
Extract Features: [178/225]	Time 0.286 (0.283)	Data 0.004 (0.007)	
Extract Features: [179/225]	Time 0.275 (0.283)	Data 0.000 (0.007)	
Extract Features: [180/225]	Time 0.280 (0.283)	Data 0.000 (0.007)	
Extract Features: [181/225]	Time 0.275 (0.283)	Data 0.000 (0.007)	
Extract Features: [182/225]	Time 0.280 (0.283)	Data 0.000 (0.007)	
Extract Features: [183/225]	Time 0.279 (0.283)	Data 0.001 (0.007)	
Extract Features: [184/225]	Time 0.287 (0.283)	Data 0.005 (0.007)	
Extract Features: [185/225]	Time 0.283 (0.283)	Data 0.000 (0.007)	
Extract Features: [186/225]	Time 0.283 (0.283)	Data 0.014 (0.007)	
Extract Features: [187/225]	Time 0.268 (0.283)	Data 0.000 (0.007)	
Extract Features: [188/225]	Time 0.282 (0.283)	Data 0.000 (0.007)	
Extract Features: [189/225]	Time 0.287 (0.283)	Data 0.002 (0.007)	
Extract Features: [190/225]	Time 0.280 (0.283)	Data 0.001 (0.007)	
Extract Features: [191/225]	Time 0.281 (0.283)	Data 0.001 (0.007)	
Extract Features: [192/225]	Time 0.289 (0.283)	Data 0.002 (0.007)	
Extract Features: [193/225]	Time 0.291 (0.283)	Data 0.009 (0.007)	
Extract Features: [194/225]	Time 0.282 (0.283)	Data 0.001 (0.007)	
Extract Features: [195/225]	Time 0.283 (0.283)	Data 0.000 (0.006)	
Extract Features: [196/225]	Time 0.284 (0.283)	Data 0.000 (0.006)	
Extract Features: [197/225]	Time 0.282 (0.283)	Data 0.001 (0.006)	
Extract Features: [198/225]	Time 0.281 (0.283)	Data 0.001 (0.006)	
Extract Features: [199/225]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [200/225]	Time 0.287 (0.283)	Data 0.006 (0.006)	
Extract Features: [201/225]	Time 0.290 (0.283)	Data 0.000 (0.006)	
Extract Features: [202/225]	Time 0.273 (0.283)	Data 0.001 (0.006)	
Extract Features: [203/225]	Time 0.278 (0.283)	Data 0.000 (0.006)	
Extract Features: [204/225]	Time 0.278 (0.283)	Data 0.002 (0.006)	
Extract Features: [205/225]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [206/225]	Time 0.274 (0.283)	Data 0.000 (0.006)	
Extract Features: [207/225]	Time 0.283 (0.283)	Data 0.000 (0.006)	
Extract Features: [208/225]	Time 0.276 (0.283)	Data 0.000 (0.006)	
Extract Features: [209/225]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [210/225]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [211/225]	Time 0.265 (0.283)	Data 0.000 (0.006)	
Extract Features: [212/225]	Time 0.267 (0.283)	Data 0.000 (0.006)	
Extract Features: [213/225]	Time 0.269 (0.282)	Data 0.000 (0.006)	
Extract Features: [214/225]	Time 0.266 (0.282)	Data 0.000 (0.006)	
Extract Features: [215/225]	Time 0.268 (0.282)	Data 0.000 (0.006)	
Extract Features: [216/225]	Time 0.267 (0.282)	Data 0.000 (0.006)	
Extract Features: [217/225]	Time 0.267 (0.282)	Data 0.000 (0.006)	
Extract Features: [218/225]	Time 0.268 (0.282)	Data 0.000 (0.006)	
Extract Features: [219/225]	Time 0.267 (0.282)	Data 0.000 (0.006)	
Extract Features: [220/225]	Time 0.268 (0.282)	Data 0.000 (0.006)	
Extract Features: [221/225]	Time 0.268 (0.282)	Data 0.000 (0.006)	
Extract Features: [222/225]	Time 0.268 (0.282)	Data 0.000 (0.006)	
Extract Features: [223/225]	Time 0.271 (0.282)	Data 0.000 (0.006)	
Extract Features: [224/225]	Time 0.267 (0.282)	Data 0.000 (0.006)	
Extract Features: [225/225]	Time 1.944 (0.289)	Data 0.000 (0.006)	
Mean AP: 21.7%
CMC Scores
  top-1          35.0%
  top-5          53.4%
  top-10         60.4%
  top-20         66.3%
Market dataset loaded
  subset   | # ids | # images
  ---------------------------
  train    |   502 |     3291
  query    |   450 |     2057
  gallery  |   933 |    33057
  camstyle  |     0 |        0
=> Loaded checkpoint 'logs/market-ide/checkpoint.pth.tar'
=> Start epoch 50 
Test:
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:49: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(self.feat.weight, mode='fan_out')
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:50: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:51: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.weight, 1)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:52: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(self.classifier.weight, std=0.001)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:61: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.classifier.bias, 0)
Extract Features: [1/17]	Time 3.272 (3.272)	Data 1.173 (1.173)	
Extract Features: [2/17]	Time 0.267 (1.770)	Data 0.000 (0.587)	
Extract Features: [3/17]	Time 0.265 (1.268)	Data 0.000 (0.391)	
Extract Features: [4/17]	Time 0.262 (1.017)	Data 0.000 (0.293)	
Extract Features: [5/17]	Time 0.266 (0.867)	Data 0.000 (0.235)	
Extract Features: [6/17]	Time 0.263 (0.766)	Data 0.000 (0.196)	
Extract Features: [7/17]	Time 0.265 (0.694)	Data 0.000 (0.168)	
Extract Features: [8/17]	Time 0.265 (0.641)	Data 0.000 (0.147)	
Extract Features: [9/17]	Time 0.263 (0.599)	Data 0.000 (0.131)	
Extract Features: [10/17]	Time 0.266 (0.565)	Data 0.000 (0.118)	
Extract Features: [11/17]	Time 0.263 (0.538)	Data 0.000 (0.107)	
Extract Features: [12/17]	Time 0.265 (0.515)	Data 0.000 (0.098)	
Extract Features: [13/17]	Time 0.264 (0.496)	Data 0.000 (0.090)	
Extract Features: [14/17]	Time 0.265 (0.479)	Data 0.000 (0.084)	
Extract Features: [15/17]	Time 0.264 (0.465)	Data 0.000 (0.078)	
Extract Features: [16/17]	Time 0.264 (0.452)	Data 0.000 (0.074)	
Extract Features: [17/17]	Time 0.527 (0.457)	Data 0.000 (0.069)	
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs = Variable(inputs, volatile=True)
Extract Features: [1/259]	Time 1.195 (1.195)	Data 0.932 (0.932)	
Extract Features: [2/259]	Time 0.272 (0.733)	Data 0.009 (0.470)	
Extract Features: [3/259]	Time 0.285 (0.584)	Data 0.016 (0.319)	
Extract Features: [4/259]	Time 0.278 (0.507)	Data 0.000 (0.239)	
Extract Features: [5/259]	Time 0.279 (0.462)	Data 0.000 (0.191)	
Extract Features: [6/259]	Time 0.270 (0.430)	Data 0.000 (0.160)	
Extract Features: [7/259]	Time 0.274 (0.408)	Data 0.000 (0.137)	
Extract Features: [8/259]	Time 0.277 (0.391)	Data 0.000 (0.120)	
Extract Features: [9/259]	Time 0.275 (0.378)	Data 0.000 (0.106)	
Extract Features: [10/259]	Time 0.273 (0.368)	Data 0.000 (0.096)	
Extract Features: [11/259]	Time 0.271 (0.359)	Data 0.000 (0.087)	
Extract Features: [12/259]	Time 0.283 (0.353)	Data 0.000 (0.080)	
Extract Features: [13/259]	Time 0.280 (0.347)	Data 0.000 (0.074)	
Extract Features: [14/259]	Time 0.280 (0.342)	Data 0.001 (0.069)	
Extract Features: [15/259]	Time 0.279 (0.338)	Data 0.002 (0.064)	
Extract Features: [16/259]	Time 0.282 (0.335)	Data 0.000 (0.060)	
Extract Features: [17/259]	Time 0.280 (0.331)	Data 0.002 (0.057)	
Extract Features: [18/259]	Time 0.280 (0.329)	Data 0.001 (0.054)	
Extract Features: [19/259]	Time 0.280 (0.326)	Data 0.001 (0.051)	
Extract Features: [20/259]	Time 0.279 (0.324)	Data 0.001 (0.048)	
Extract Features: [21/259]	Time 0.279 (0.322)	Data 0.001 (0.046)	
Extract Features: [22/259]	Time 0.287 (0.320)	Data 0.006 (0.044)	
Extract Features: [23/259]	Time 0.270 (0.318)	Data 0.000 (0.042)	
Extract Features: [24/259]	Time 0.275 (0.316)	Data 0.000 (0.041)	
Extract Features: [25/259]	Time 0.278 (0.314)	Data 0.000 (0.039)	
Extract Features: [26/259]	Time 0.280 (0.313)	Data 0.001 (0.038)	
Extract Features: [27/259]	Time 0.276 (0.312)	Data 0.002 (0.036)	
Extract Features: [28/259]	Time 0.276 (0.310)	Data 0.000 (0.035)	
Extract Features: [29/259]	Time 0.271 (0.309)	Data 0.000 (0.034)	
Extract Features: [30/259]	Time 0.278 (0.308)	Data 0.000 (0.033)	
Extract Features: [31/259]	Time 0.282 (0.307)	Data 0.006 (0.032)	
Extract Features: [32/259]	Time 0.276 (0.306)	Data 0.001 (0.031)	
Extract Features: [33/259]	Time 0.274 (0.305)	Data 0.000 (0.030)	
Extract Features: [34/259]	Time 0.277 (0.304)	Data 0.000 (0.029)	
Extract Features: [35/259]	Time 0.274 (0.304)	Data 0.001 (0.028)	
Extract Features: [36/259]	Time 0.280 (0.303)	Data 0.000 (0.027)	
Extract Features: [37/259]	Time 0.270 (0.302)	Data 0.000 (0.027)	
Extract Features: [38/259]	Time 0.275 (0.301)	Data 0.000 (0.026)	
Extract Features: [39/259]	Time 0.270 (0.301)	Data 0.000 (0.025)	
Extract Features: [40/259]	Time 0.271 (0.300)	Data 0.000 (0.025)	
Extract Features: [41/259]	Time 0.278 (0.299)	Data 0.000 (0.024)	
Extract Features: [42/259]	Time 0.274 (0.299)	Data 0.000 (0.024)	
Extract Features: [43/259]	Time 0.279 (0.298)	Data 0.001 (0.023)	
Extract Features: [44/259]	Time 0.353 (0.299)	Data 0.003 (0.023)	
Extract Features: [45/259]	Time 0.276 (0.299)	Data 0.000 (0.022)	
Extract Features: [46/259]	Time 0.281 (0.299)	Data 0.001 (0.022)	
Extract Features: [47/259]	Time 0.280 (0.298)	Data 0.000 (0.021)	
Extract Features: [48/259]	Time 0.279 (0.298)	Data 0.001 (0.021)	
Extract Features: [49/259]	Time 0.278 (0.297)	Data 0.000 (0.020)	
Extract Features: [50/259]	Time 0.278 (0.297)	Data 0.000 (0.020)	
Extract Features: [51/259]	Time 0.275 (0.297)	Data 0.000 (0.020)	
Extract Features: [52/259]	Time 0.267 (0.296)	Data 0.000 (0.019)	
Extract Features: [53/259]	Time 0.270 (0.295)	Data 0.000 (0.019)	
Extract Features: [54/259]	Time 0.273 (0.295)	Data 0.000 (0.018)	
Extract Features: [55/259]	Time 0.279 (0.295)	Data 0.000 (0.018)	
Extract Features: [56/259]	Time 0.279 (0.294)	Data 0.000 (0.018)	
Extract Features: [57/259]	Time 0.276 (0.294)	Data 0.000 (0.018)	
Extract Features: [58/259]	Time 0.274 (0.294)	Data 0.000 (0.017)	
Extract Features: [59/259]	Time 0.285 (0.294)	Data 0.000 (0.017)	
Extract Features: [60/259]	Time 0.279 (0.293)	Data 0.001 (0.017)	
Extract Features: [61/259]	Time 0.281 (0.293)	Data 0.000 (0.016)	
Extract Features: [62/259]	Time 0.273 (0.293)	Data 0.001 (0.016)	
Extract Features: [63/259]	Time 0.275 (0.293)	Data 0.004 (0.016)	
Extract Features: [64/259]	Time 0.279 (0.292)	Data 0.000 (0.016)	
Extract Features: [65/259]	Time 0.282 (0.292)	Data 0.010 (0.016)	
Extract Features: [66/259]	Time 0.283 (0.292)	Data 0.000 (0.015)	
Extract Features: [67/259]	Time 0.304 (0.292)	Data 0.015 (0.015)	
Extract Features: [68/259]	Time 0.289 (0.292)	Data 0.000 (0.015)	
Extract Features: [69/259]	Time 0.324 (0.293)	Data 0.037 (0.015)	
Extract Features: [70/259]	Time 0.277 (0.292)	Data 0.001 (0.015)	
Extract Features: [71/259]	Time 0.279 (0.292)	Data 0.001 (0.015)	
Extract Features: [72/259]	Time 0.280 (0.292)	Data 0.001 (0.015)	
Extract Features: [73/259]	Time 0.287 (0.292)	Data 0.006 (0.015)	
Extract Features: [74/259]	Time 0.276 (0.292)	Data 0.000 (0.015)	
Extract Features: [75/259]	Time 0.274 (0.292)	Data 0.000 (0.014)	
Extract Features: [76/259]	Time 0.276 (0.291)	Data 0.003 (0.014)	
Extract Features: [77/259]	Time 0.280 (0.291)	Data 0.001 (0.014)	
Extract Features: [78/259]	Time 0.280 (0.291)	Data 0.000 (0.014)	
Extract Features: [79/259]	Time 0.279 (0.291)	Data 0.001 (0.014)	
Extract Features: [80/259]	Time 0.278 (0.291)	Data 0.000 (0.014)	
Extract Features: [81/259]	Time 0.279 (0.291)	Data 0.006 (0.013)	
Extract Features: [82/259]	Time 0.280 (0.291)	Data 0.000 (0.013)	
Extract Features: [83/259]	Time 0.283 (0.290)	Data 0.000 (0.013)	
Extract Features: [84/259]	Time 0.268 (0.290)	Data 0.001 (0.013)	
Extract Features: [85/259]	Time 0.292 (0.290)	Data 0.004 (0.013)	
Extract Features: [86/259]	Time 0.287 (0.290)	Data 0.006 (0.013)	
Extract Features: [87/259]	Time 0.275 (0.290)	Data 0.000 (0.013)	
Extract Features: [88/259]	Time 0.278 (0.290)	Data 0.000 (0.012)	
Extract Features: [89/259]	Time 0.281 (0.290)	Data 0.001 (0.012)	
Extract Features: [90/259]	Time 0.280 (0.290)	Data 0.000 (0.012)	
Extract Features: [91/259]	Time 0.286 (0.290)	Data 0.010 (0.012)	
Extract Features: [92/259]	Time 0.274 (0.289)	Data 0.000 (0.012)	
Extract Features: [93/259]	Time 0.266 (0.289)	Data 0.000 (0.012)	
Extract Features: [94/259]	Time 0.283 (0.289)	Data 0.001 (0.012)	
Extract Features: [95/259]	Time 0.281 (0.289)	Data 0.001 (0.012)	
Extract Features: [96/259]	Time 0.281 (0.289)	Data 0.001 (0.012)	
Extract Features: [97/259]	Time 0.280 (0.289)	Data 0.001 (0.011)	
Extract Features: [98/259]	Time 0.279 (0.289)	Data 0.000 (0.011)	
Extract Features: [99/259]	Time 0.289 (0.289)	Data 0.001 (0.011)	
Extract Features: [100/259]	Time 0.289 (0.289)	Data 0.010 (0.011)	
Extract Features: [101/259]	Time 0.286 (0.289)	Data 0.001 (0.011)	
Extract Features: [102/259]	Time 0.276 (0.289)	Data 0.000 (0.011)	
Extract Features: [103/259]	Time 0.266 (0.288)	Data 0.000 (0.011)	
Extract Features: [104/259]	Time 0.275 (0.288)	Data 0.001 (0.011)	
Extract Features: [105/259]	Time 0.269 (0.288)	Data 0.002 (0.011)	
Extract Features: [106/259]	Time 0.272 (0.288)	Data 0.001 (0.011)	
Extract Features: [107/259]	Time 0.278 (0.288)	Data 0.000 (0.011)	
Extract Features: [108/259]	Time 0.288 (0.288)	Data 0.001 (0.010)	
Extract Features: [109/259]	Time 0.280 (0.288)	Data 0.000 (0.010)	
Extract Features: [110/259]	Time 0.275 (0.288)	Data 0.001 (0.010)	
Extract Features: [111/259]	Time 0.293 (0.288)	Data 0.004 (0.010)	
Extract Features: [112/259]	Time 0.275 (0.288)	Data 0.000 (0.010)	
Extract Features: [113/259]	Time 0.279 (0.287)	Data 0.000 (0.010)	
Extract Features: [114/259]	Time 0.283 (0.287)	Data 0.001 (0.010)	
Extract Features: [115/259]	Time 0.297 (0.288)	Data 0.000 (0.010)	
Extract Features: [116/259]	Time 0.283 (0.287)	Data 0.017 (0.010)	
Extract Features: [117/259]	Time 0.266 (0.287)	Data 0.000 (0.010)	
Extract Features: [118/259]	Time 0.273 (0.287)	Data 0.000 (0.010)	
Extract Features: [119/259]	Time 0.279 (0.287)	Data 0.003 (0.010)	
Extract Features: [120/259]	Time 0.274 (0.287)	Data 0.000 (0.010)	
Extract Features: [121/259]	Time 0.277 (0.287)	Data 0.000 (0.010)	
Extract Features: [122/259]	Time 0.290 (0.287)	Data 0.000 (0.010)	
Extract Features: [123/259]	Time 0.268 (0.287)	Data 0.001 (0.009)	
Extract Features: [124/259]	Time 0.273 (0.287)	Data 0.000 (0.009)	
Extract Features: [125/259]	Time 0.270 (0.287)	Data 0.000 (0.009)	
Extract Features: [126/259]	Time 0.279 (0.286)	Data 0.000 (0.009)	
Extract Features: [127/259]	Time 0.273 (0.286)	Data 0.001 (0.009)	
Extract Features: [128/259]	Time 0.271 (0.286)	Data 0.000 (0.009)	
Extract Features: [129/259]	Time 0.277 (0.286)	Data 0.000 (0.009)	
Extract Features: [130/259]	Time 0.278 (0.286)	Data 0.000 (0.009)	
Extract Features: [131/259]	Time 0.282 (0.286)	Data 0.000 (0.009)	
Extract Features: [132/259]	Time 0.276 (0.286)	Data 0.001 (0.009)	
Extract Features: [133/259]	Time 0.274 (0.286)	Data 0.001 (0.009)	
Extract Features: [134/259]	Time 0.280 (0.286)	Data 0.000 (0.009)	
Extract Features: [135/259]	Time 0.275 (0.286)	Data 0.001 (0.009)	
Extract Features: [136/259]	Time 0.270 (0.286)	Data 0.000 (0.009)	
Extract Features: [137/259]	Time 0.280 (0.286)	Data 0.000 (0.009)	
Extract Features: [138/259]	Time 0.283 (0.286)	Data 0.000 (0.008)	
Extract Features: [139/259]	Time 0.280 (0.286)	Data 0.000 (0.008)	
Extract Features: [140/259]	Time 0.281 (0.286)	Data 0.000 (0.008)	
Extract Features: [141/259]	Time 0.269 (0.285)	Data 0.002 (0.008)	
Extract Features: [142/259]	Time 0.278 (0.285)	Data 0.001 (0.008)	
Extract Features: [143/259]	Time 0.280 (0.285)	Data 0.000 (0.008)	
Extract Features: [144/259]	Time 0.273 (0.285)	Data 0.001 (0.008)	
Extract Features: [145/259]	Time 0.278 (0.285)	Data 0.000 (0.008)	
Extract Features: [146/259]	Time 0.281 (0.285)	Data 0.000 (0.008)	
Extract Features: [147/259]	Time 0.289 (0.285)	Data 0.006 (0.008)	
Extract Features: [148/259]	Time 0.268 (0.285)	Data 0.000 (0.008)	
Extract Features: [149/259]	Time 0.282 (0.285)	Data 0.001 (0.008)	
Extract Features: [150/259]	Time 0.286 (0.285)	Data 0.007 (0.008)	
Extract Features: [151/259]	Time 0.275 (0.285)	Data 0.000 (0.008)	
Extract Features: [152/259]	Time 0.273 (0.285)	Data 0.000 (0.008)	
Extract Features: [153/259]	Time 0.275 (0.285)	Data 0.000 (0.008)	
Extract Features: [154/259]	Time 0.274 (0.285)	Data 0.001 (0.008)	
Extract Features: [155/259]	Time 0.286 (0.285)	Data 0.000 (0.008)	
Extract Features: [156/259]	Time 0.272 (0.285)	Data 0.000 (0.008)	
Extract Features: [157/259]	Time 0.272 (0.285)	Data 0.000 (0.008)	
Extract Features: [158/259]	Time 0.271 (0.285)	Data 0.000 (0.008)	
Extract Features: [159/259]	Time 0.285 (0.285)	Data 0.001 (0.007)	
Extract Features: [160/259]	Time 0.274 (0.284)	Data 0.000 (0.007)	
Extract Features: [161/259]	Time 0.276 (0.284)	Data 0.000 (0.007)	
Extract Features: [162/259]	Time 0.277 (0.284)	Data 0.000 (0.007)	
Extract Features: [163/259]	Time 0.281 (0.284)	Data 0.000 (0.007)	
Extract Features: [164/259]	Time 0.282 (0.284)	Data 0.001 (0.007)	
Extract Features: [165/259]	Time 0.279 (0.284)	Data 0.001 (0.007)	
Extract Features: [166/259]	Time 0.280 (0.284)	Data 0.000 (0.007)	
Extract Features: [167/259]	Time 0.281 (0.284)	Data 0.000 (0.007)	
Extract Features: [168/259]	Time 0.280 (0.284)	Data 0.000 (0.007)	
Extract Features: [169/259]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [170/259]	Time 0.268 (0.284)	Data 0.000 (0.007)	
Extract Features: [171/259]	Time 0.310 (0.284)	Data 0.023 (0.007)	
Extract Features: [172/259]	Time 0.273 (0.284)	Data 0.000 (0.007)	
Extract Features: [173/259]	Time 0.278 (0.284)	Data 0.000 (0.007)	
Extract Features: [174/259]	Time 0.266 (0.284)	Data 0.000 (0.007)	
Extract Features: [175/259]	Time 0.282 (0.284)	Data 0.002 (0.007)	
Extract Features: [176/259]	Time 0.273 (0.284)	Data 0.001 (0.007)	
Extract Features: [177/259]	Time 0.267 (0.284)	Data 0.000 (0.007)	
Extract Features: [178/259]	Time 0.295 (0.284)	Data 0.003 (0.007)	
Extract Features: [179/259]	Time 0.267 (0.284)	Data 0.000 (0.007)	
Extract Features: [180/259]	Time 0.273 (0.284)	Data 0.001 (0.007)	
Extract Features: [181/259]	Time 0.269 (0.284)	Data 0.000 (0.007)	
Extract Features: [182/259]	Time 0.280 (0.284)	Data 0.004 (0.007)	
Extract Features: [183/259]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [184/259]	Time 0.278 (0.284)	Data 0.001 (0.007)	
Extract Features: [185/259]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [186/259]	Time 0.284 (0.284)	Data 0.004 (0.007)	
Extract Features: [187/259]	Time 0.287 (0.284)	Data 0.001 (0.007)	
Extract Features: [188/259]	Time 0.289 (0.284)	Data 0.000 (0.007)	
Extract Features: [189/259]	Time 0.272 (0.284)	Data 0.000 (0.007)	
Extract Features: [190/259]	Time 0.275 (0.284)	Data 0.003 (0.007)	
Extract Features: [191/259]	Time 0.269 (0.283)	Data 0.000 (0.006)	
Extract Features: [192/259]	Time 0.283 (0.283)	Data 0.002 (0.006)	
Extract Features: [193/259]	Time 0.284 (0.283)	Data 0.001 (0.006)	
Extract Features: [194/259]	Time 0.278 (0.283)	Data 0.001 (0.006)	
Extract Features: [195/259]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [196/259]	Time 0.280 (0.283)	Data 0.001 (0.006)	
Extract Features: [197/259]	Time 0.283 (0.283)	Data 0.000 (0.006)	
Extract Features: [198/259]	Time 0.275 (0.283)	Data 0.003 (0.006)	
Extract Features: [199/259]	Time 0.276 (0.283)	Data 0.000 (0.006)	
Extract Features: [200/259]	Time 0.267 (0.283)	Data 0.000 (0.006)	
Extract Features: [201/259]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [202/259]	Time 0.281 (0.283)	Data 0.000 (0.006)	
Extract Features: [203/259]	Time 0.271 (0.283)	Data 0.000 (0.006)	
Extract Features: [204/259]	Time 0.281 (0.283)	Data 0.000 (0.006)	
Extract Features: [205/259]	Time 0.278 (0.283)	Data 0.000 (0.006)	
Extract Features: [206/259]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [207/259]	Time 0.270 (0.283)	Data 0.002 (0.006)	
Extract Features: [208/259]	Time 0.277 (0.283)	Data 0.000 (0.006)	
Extract Features: [209/259]	Time 0.283 (0.283)	Data 0.004 (0.006)	
Extract Features: [210/259]	Time 0.284 (0.283)	Data 0.001 (0.006)	
Extract Features: [211/259]	Time 0.278 (0.283)	Data 0.000 (0.006)	
Extract Features: [212/259]	Time 0.284 (0.283)	Data 0.005 (0.006)	
Extract Features: [213/259]	Time 0.275 (0.283)	Data 0.000 (0.006)	
Extract Features: [214/259]	Time 0.278 (0.283)	Data 0.001 (0.006)	
Extract Features: [215/259]	Time 0.281 (0.283)	Data 0.002 (0.006)	
Extract Features: [216/259]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [217/259]	Time 0.280 (0.283)	Data 0.001 (0.006)	
Extract Features: [218/259]	Time 0.269 (0.283)	Data 0.000 (0.006)	
Extract Features: [219/259]	Time 0.283 (0.283)	Data 0.002 (0.006)	
Extract Features: [220/259]	Time 0.272 (0.283)	Data 0.000 (0.006)	
Extract Features: [221/259]	Time 0.277 (0.283)	Data 0.000 (0.006)	
Extract Features: [222/259]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [223/259]	Time 0.272 (0.283)	Data 0.001 (0.006)	
Extract Features: [224/259]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [225/259]	Time 0.275 (0.283)	Data 0.001 (0.006)	
Extract Features: [226/259]	Time 0.275 (0.283)	Data 0.000 (0.006)	
Extract Features: [227/259]	Time 0.290 (0.283)	Data 0.000 (0.006)	
Extract Features: [228/259]	Time 0.270 (0.283)	Data 0.000 (0.006)	
Extract Features: [229/259]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [230/259]	Time 0.275 (0.283)	Data 0.001 (0.006)	
Extract Features: [231/259]	Time 0.273 (0.283)	Data 0.000 (0.005)	
Extract Features: [232/259]	Time 0.272 (0.282)	Data 0.000 (0.005)	
Extract Features: [233/259]	Time 0.280 (0.282)	Data 0.000 (0.005)	
Extract Features: [234/259]	Time 0.278 (0.282)	Data 0.000 (0.005)	
Extract Features: [235/259]	Time 0.280 (0.282)	Data 0.000 (0.005)	
Extract Features: [236/259]	Time 0.276 (0.282)	Data 0.000 (0.005)	
Extract Features: [237/259]	Time 0.272 (0.282)	Data 0.000 (0.005)	
Extract Features: [238/259]	Time 0.272 (0.282)	Data 0.000 (0.005)	
Extract Features: [239/259]	Time 0.279 (0.282)	Data 0.004 (0.005)	
Extract Features: [240/259]	Time 0.281 (0.282)	Data 0.000 (0.005)	
Extract Features: [241/259]	Time 0.281 (0.282)	Data 0.001 (0.005)	
Extract Features: [242/259]	Time 0.290 (0.282)	Data 0.003 (0.005)	
Extract Features: [243/259]	Time 0.286 (0.282)	Data 0.000 (0.005)	
Extract Features: [244/259]	Time 0.266 (0.282)	Data 0.000 (0.005)	
Extract Features: [245/259]	Time 0.268 (0.282)	Data 0.000 (0.005)	
Extract Features: [246/259]	Time 0.266 (0.282)	Data 0.000 (0.005)	
Extract Features: [247/259]	Time 0.268 (0.282)	Data 0.000 (0.005)	/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:66: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  dist.addmm_(1, -2, x, y.t())

Extract Features: [248/259]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [249/259]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [250/259]	Time 0.268 (0.282)	Data 0.000 (0.005)	
Extract Features: [251/259]	Time 0.265 (0.282)	Data 0.000 (0.005)	
Extract Features: [252/259]	Time 0.269 (0.282)	Data 0.000 (0.005)	
Extract Features: [253/259]	Time 0.266 (0.282)	Data 0.000 (0.005)	
Extract Features: [254/259]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [255/259]	Time 0.270 (0.282)	Data 0.000 (0.005)	
Extract Features: [256/259]	Time 0.266 (0.282)	Data 0.000 (0.005)	
Extract Features: [257/259]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [258/259]	Time 0.266 (0.281)	Data 0.000 (0.005)	
Extract Features: [259/259]	Time 0.921 (0.284)	Data 0.000 (0.005)	
Mean AP: 23.0%
CMC Scores
  top-1          37.9%
  top-5          56.5%
  top-10         63.1%
  top-20         68.5%
Market dataset loaded
  subset   | # ids | # images
  ---------------------------
  train    |   502 |     3291
  query    |   450 |     2057
  gallery  |   934 |    28091
  camstyle  |     0 |        0
=> Loaded checkpoint 'logs/market-ide/checkpoint.pth.tar'
=> Start epoch 50 
Test:
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:49: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(self.feat.weight, mode='fan_out')
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:50: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:51: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.weight, 1)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:52: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(self.classifier.weight, std=0.001)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:61: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.classifier.bias, 0)
Extract Features: [1/17]	Time 3.315 (3.315)	Data 1.262 (1.262)	
Extract Features: [2/17]	Time 0.265 (1.790)	Data 0.000 (0.631)	
Extract Features: [3/17]	Time 0.264 (1.281)	Data 0.000 (0.421)	
Extract Features: [4/17]	Time 0.262 (1.026)	Data 0.000 (0.316)	
Extract Features: [5/17]	Time 0.265 (0.874)	Data 0.000 (0.253)	
Extract Features: [6/17]	Time 0.263 (0.772)	Data 0.000 (0.210)	
Extract Features: [7/17]	Time 0.265 (0.700)	Data 0.000 (0.180)	
Extract Features: [8/17]	Time 0.263 (0.645)	Data 0.000 (0.158)	
Extract Features: [9/17]	Time 0.266 (0.603)	Data 0.000 (0.140)	
Extract Features: [10/17]	Time 0.263 (0.569)	Data 0.000 (0.126)	
Extract Features: [11/17]	Time 0.264 (0.541)	Data 0.000 (0.115)	
Extract Features: [12/17]	Time 0.266 (0.518)	Data 0.000 (0.105)	
Extract Features: [13/17]	Time 0.264 (0.499)	Data 0.000 (0.097)	
Extract Features: [14/17]	Time 0.267 (0.482)	Data 0.000 (0.090)	
Extract Features: [15/17]	Time 0.264 (0.468)	Data 0.000 (0.084)	
Extract Features: [16/17]	Time 0.264 (0.455)	Data 0.000 (0.079)	
Extract Features: [17/17]	Time 0.545 (0.460)	Data 0.000 (0.074)	
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs = Variable(inputs, volatile=True)
Extract Features: [1/220]	Time 1.441 (1.441)	Data 1.165 (1.165)	
Extract Features: [2/220]	Time 0.267 (0.854)	Data 0.000 (0.583)	
Extract Features: [3/220]	Time 0.277 (0.662)	Data 0.000 (0.389)	
Extract Features: [4/220]	Time 0.272 (0.564)	Data 0.001 (0.292)	
Extract Features: [5/220]	Time 0.271 (0.506)	Data 0.000 (0.233)	
Extract Features: [6/220]	Time 0.278 (0.468)	Data 0.002 (0.195)	
Extract Features: [7/220]	Time 0.279 (0.441)	Data 0.001 (0.167)	
Extract Features: [8/220]	Time 0.292 (0.422)	Data 0.016 (0.148)	
Extract Features: [9/220]	Time 0.278 (0.406)	Data 0.001 (0.132)	
Extract Features: [10/220]	Time 0.293 (0.395)	Data 0.021 (0.121)	
Extract Features: [11/220]	Time 0.295 (0.386)	Data 0.016 (0.111)	
Extract Features: [12/220]	Time 0.274 (0.376)	Data 0.000 (0.102)	
Extract Features: [13/220]	Time 0.277 (0.369)	Data 0.001 (0.094)	
Extract Features: [14/220]	Time 0.280 (0.362)	Data 0.001 (0.088)	
Extract Features: [15/220]	Time 0.279 (0.357)	Data 0.001 (0.082)	
Extract Features: [16/220]	Time 0.282 (0.352)	Data 0.005 (0.077)	
Extract Features: [17/220]	Time 0.280 (0.348)	Data 0.001 (0.072)	
Extract Features: [18/220]	Time 0.280 (0.344)	Data 0.002 (0.069)	
Extract Features: [19/220]	Time 0.279 (0.341)	Data 0.001 (0.065)	
Extract Features: [20/220]	Time 0.274 (0.337)	Data 0.001 (0.062)	
Extract Features: [21/220]	Time 0.271 (0.334)	Data 0.000 (0.059)	
Extract Features: [22/220]	Time 0.276 (0.332)	Data 0.000 (0.056)	
Extract Features: [23/220]	Time 0.279 (0.329)	Data 0.001 (0.054)	
Extract Features: [24/220]	Time 0.279 (0.327)	Data 0.001 (0.052)	
Extract Features: [25/220]	Time 0.271 (0.325)	Data 0.001 (0.050)	
Extract Features: [26/220]	Time 0.281 (0.323)	Data 0.000 (0.048)	
Extract Features: [27/220]	Time 0.272 (0.321)	Data 0.001 (0.046)	
Extract Features: [28/220]	Time 0.277 (0.320)	Data 0.001 (0.044)	
Extract Features: [29/220]	Time 0.280 (0.318)	Data 0.001 (0.043)	
Extract Features: [30/220]	Time 0.280 (0.317)	Data 0.001 (0.041)	
Extract Features: [31/220]	Time 0.280 (0.316)	Data 0.001 (0.040)	
Extract Features: [32/220]	Time 0.274 (0.315)	Data 0.001 (0.039)	
Extract Features: [33/220]	Time 0.269 (0.313)	Data 0.000 (0.038)	
Extract Features: [34/220]	Time 0.270 (0.312)	Data 0.000 (0.037)	
Extract Features: [35/220]	Time 0.273 (0.311)	Data 0.000 (0.036)	
Extract Features: [36/220]	Time 0.270 (0.310)	Data 0.000 (0.035)	
Extract Features: [37/220]	Time 0.272 (0.309)	Data 0.000 (0.034)	
Extract Features: [38/220]	Time 0.272 (0.308)	Data 0.000 (0.033)	
Extract Features: [39/220]	Time 0.278 (0.307)	Data 0.000 (0.032)	
Extract Features: [40/220]	Time 0.273 (0.306)	Data 0.000 (0.031)	
Extract Features: [41/220]	Time 0.265 (0.305)	Data 0.001 (0.030)	
Extract Features: [42/220]	Time 0.285 (0.305)	Data 0.000 (0.030)	
Extract Features: [43/220]	Time 0.284 (0.304)	Data 0.000 (0.029)	
Extract Features: [44/220]	Time 0.270 (0.303)	Data 0.000 (0.028)	
Extract Features: [45/220]	Time 0.278 (0.303)	Data 0.000 (0.028)	
Extract Features: [46/220]	Time 0.285 (0.302)	Data 0.005 (0.027)	
Extract Features: [47/220]	Time 0.275 (0.302)	Data 0.000 (0.027)	
Extract Features: [48/220]	Time 0.275 (0.301)	Data 0.001 (0.026)	
Extract Features: [49/220]	Time 0.265 (0.301)	Data 0.001 (0.026)	
Extract Features: [50/220]	Time 0.273 (0.300)	Data 0.001 (0.025)	
Extract Features: [51/220]	Time 0.268 (0.299)	Data 0.000 (0.025)	
Extract Features: [52/220]	Time 0.264 (0.299)	Data 0.001 (0.024)	
Extract Features: [53/220]	Time 0.281 (0.298)	Data 0.000 (0.024)	
Extract Features: [54/220]	Time 0.274 (0.298)	Data 0.000 (0.023)	
Extract Features: [55/220]	Time 0.278 (0.298)	Data 0.000 (0.023)	
Extract Features: [56/220]	Time 0.280 (0.297)	Data 0.001 (0.022)	
Extract Features: [57/220]	Time 0.269 (0.297)	Data 0.000 (0.022)	
Extract Features: [58/220]	Time 0.289 (0.297)	Data 0.002 (0.022)	
Extract Features: [59/220]	Time 0.276 (0.296)	Data 0.001 (0.021)	
Extract Features: [60/220]	Time 0.278 (0.296)	Data 0.000 (0.021)	
Extract Features: [61/220]	Time 0.358 (0.297)	Data 0.001 (0.021)	
Extract Features: [62/220]	Time 0.271 (0.297)	Data 0.000 (0.020)	
Extract Features: [63/220]	Time 0.290 (0.296)	Data 0.010 (0.020)	
Extract Features: [64/220]	Time 0.280 (0.296)	Data 0.001 (0.020)	
Extract Features: [65/220]	Time 0.278 (0.296)	Data 0.000 (0.020)	
Extract Features: [66/220]	Time 0.282 (0.296)	Data 0.003 (0.019)	
Extract Features: [67/220]	Time 0.280 (0.295)	Data 0.000 (0.019)	
Extract Features: [68/220]	Time 0.267 (0.295)	Data 0.001 (0.019)	
Extract Features: [69/220]	Time 0.271 (0.295)	Data 0.000 (0.019)	
Extract Features: [70/220]	Time 0.279 (0.294)	Data 0.000 (0.018)	
Extract Features: [71/220]	Time 0.272 (0.294)	Data 0.000 (0.018)	
Extract Features: [72/220]	Time 0.273 (0.294)	Data 0.000 (0.018)	
Extract Features: [73/220]	Time 0.272 (0.294)	Data 0.000 (0.018)	
Extract Features: [74/220]	Time 0.276 (0.293)	Data 0.000 (0.017)	
Extract Features: [75/220]	Time 0.279 (0.293)	Data 0.001 (0.017)	
Extract Features: [76/220]	Time 0.279 (0.293)	Data 0.001 (0.017)	
Extract Features: [77/220]	Time 0.280 (0.293)	Data 0.003 (0.017)	
Extract Features: [78/220]	Time 0.281 (0.293)	Data 0.000 (0.016)	
Extract Features: [79/220]	Time 0.279 (0.292)	Data 0.000 (0.016)	
Extract Features: [80/220]	Time 0.267 (0.292)	Data 0.001 (0.016)	
Extract Features: [81/220]	Time 0.276 (0.292)	Data 0.000 (0.016)	
Extract Features: [82/220]	Time 0.266 (0.292)	Data 0.002 (0.016)	
Extract Features: [83/220]	Time 0.288 (0.292)	Data 0.000 (0.016)	
Extract Features: [84/220]	Time 0.273 (0.291)	Data 0.006 (0.015)	
Extract Features: [85/220]	Time 0.284 (0.291)	Data 0.006 (0.015)	
Extract Features: [86/220]	Time 0.273 (0.291)	Data 0.000 (0.015)	
Extract Features: [87/220]	Time 0.277 (0.291)	Data 0.000 (0.015)	
Extract Features: [88/220]	Time 0.284 (0.291)	Data 0.017 (0.015)	
Extract Features: [89/220]	Time 0.276 (0.291)	Data 0.000 (0.015)	
Extract Features: [90/220]	Time 0.279 (0.290)	Data 0.000 (0.015)	
Extract Features: [91/220]	Time 0.272 (0.290)	Data 0.000 (0.014)	
Extract Features: [92/220]	Time 0.273 (0.290)	Data 0.000 (0.014)	
Extract Features: [93/220]	Time 0.274 (0.290)	Data 0.004 (0.014)	
Extract Features: [94/220]	Time 0.281 (0.290)	Data 0.002 (0.014)	
Extract Features: [95/220]	Time 0.275 (0.290)	Data 0.001 (0.014)	
Extract Features: [96/220]	Time 0.270 (0.289)	Data 0.000 (0.014)	
Extract Features: [97/220]	Time 0.276 (0.289)	Data 0.000 (0.014)	
Extract Features: [98/220]	Time 0.281 (0.289)	Data 0.000 (0.014)	
Extract Features: [99/220]	Time 0.276 (0.289)	Data 0.000 (0.013)	
Extract Features: [100/220]	Time 0.277 (0.289)	Data 0.000 (0.013)	
Extract Features: [101/220]	Time 0.277 (0.289)	Data 0.000 (0.013)	
Extract Features: [102/220]	Time 0.267 (0.289)	Data 0.000 (0.013)	
Extract Features: [103/220]	Time 0.283 (0.289)	Data 0.000 (0.013)	
Extract Features: [104/220]	Time 0.280 (0.289)	Data 0.003 (0.013)	
Extract Features: [105/220]	Time 0.272 (0.288)	Data 0.001 (0.013)	
Extract Features: [106/220]	Time 0.278 (0.288)	Data 0.000 (0.013)	
Extract Features: [107/220]	Time 0.280 (0.288)	Data 0.000 (0.012)	
Extract Features: [108/220]	Time 0.274 (0.288)	Data 0.001 (0.012)	
Extract Features: [109/220]	Time 0.287 (0.288)	Data 0.000 (0.012)	
Extract Features: [110/220]	Time 0.275 (0.288)	Data 0.004 (0.012)	
Extract Features: [111/220]	Time 0.272 (0.288)	Data 0.000 (0.012)	
Extract Features: [112/220]	Time 0.282 (0.288)	Data 0.000 (0.012)	
Extract Features: [113/220]	Time 0.280 (0.288)	Data 0.000 (0.012)	
Extract Features: [114/220]	Time 0.279 (0.288)	Data 0.013 (0.012)	
Extract Features: [115/220]	Time 0.273 (0.287)	Data 0.000 (0.012)	
Extract Features: [116/220]	Time 0.268 (0.287)	Data 0.000 (0.012)	
Extract Features: [117/220]	Time 0.290 (0.287)	Data 0.000 (0.012)	
Extract Features: [118/220]	Time 0.284 (0.287)	Data 0.001 (0.011)	
Extract Features: [119/220]	Time 0.276 (0.287)	Data 0.000 (0.011)	
Extract Features: [120/220]	Time 0.279 (0.287)	Data 0.000 (0.011)	
Extract Features: [121/220]	Time 0.289 (0.287)	Data 0.006 (0.011)	
Extract Features: [122/220]	Time 0.279 (0.287)	Data 0.001 (0.011)	
Extract Features: [123/220]	Time 0.281 (0.287)	Data 0.000 (0.011)	
Extract Features: [124/220]	Time 0.277 (0.287)	Data 0.001 (0.011)	/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:66: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  dist.addmm_(1, -2, x, y.t())

Extract Features: [125/220]	Time 0.284 (0.287)	Data 0.000 (0.011)	
Extract Features: [126/220]	Time 0.278 (0.287)	Data 0.010 (0.011)	
Extract Features: [127/220]	Time 0.285 (0.287)	Data 0.000 (0.011)	
Extract Features: [128/220]	Time 0.279 (0.287)	Data 0.000 (0.011)	
Extract Features: [129/220]	Time 0.280 (0.287)	Data 0.000 (0.011)	
Extract Features: [130/220]	Time 0.281 (0.287)	Data 0.000 (0.011)	
Extract Features: [131/220]	Time 0.271 (0.287)	Data 0.000 (0.010)	
Extract Features: [132/220]	Time 0.279 (0.286)	Data 0.003 (0.010)	
Extract Features: [133/220]	Time 0.280 (0.286)	Data 0.000 (0.010)	
Extract Features: [134/220]	Time 0.279 (0.286)	Data 0.000 (0.010)	
Extract Features: [135/220]	Time 0.272 (0.286)	Data 0.000 (0.010)	
Extract Features: [136/220]	Time 0.274 (0.286)	Data 0.000 (0.010)	
Extract Features: [137/220]	Time 0.275 (0.286)	Data 0.000 (0.010)	
Extract Features: [138/220]	Time 0.279 (0.286)	Data 0.000 (0.010)	
Extract Features: [139/220]	Time 0.277 (0.286)	Data 0.005 (0.010)	
Extract Features: [140/220]	Time 0.277 (0.286)	Data 0.006 (0.010)	
Extract Features: [141/220]	Time 0.276 (0.286)	Data 0.000 (0.010)	
Extract Features: [142/220]	Time 0.269 (0.286)	Data 0.000 (0.010)	
Extract Features: [143/220]	Time 0.273 (0.286)	Data 0.000 (0.010)	
Extract Features: [144/220]	Time 0.278 (0.286)	Data 0.000 (0.010)	
Extract Features: [145/220]	Time 0.280 (0.286)	Data 0.003 (0.010)	
Extract Features: [146/220]	Time 0.279 (0.286)	Data 0.000 (0.010)	
Extract Features: [147/220]	Time 0.293 (0.286)	Data 0.011 (0.010)	
Extract Features: [148/220]	Time 0.272 (0.285)	Data 0.000 (0.009)	
Extract Features: [149/220]	Time 0.277 (0.285)	Data 0.000 (0.009)	
Extract Features: [150/220]	Time 0.273 (0.285)	Data 0.000 (0.009)	
Extract Features: [151/220]	Time 0.278 (0.285)	Data 0.000 (0.009)	
Extract Features: [152/220]	Time 0.273 (0.285)	Data 0.002 (0.009)	
Extract Features: [153/220]	Time 0.269 (0.285)	Data 0.000 (0.009)	
Extract Features: [154/220]	Time 0.266 (0.285)	Data 0.000 (0.009)	
Extract Features: [155/220]	Time 0.276 (0.285)	Data 0.003 (0.009)	
Extract Features: [156/220]	Time 0.269 (0.285)	Data 0.000 (0.009)	
Extract Features: [157/220]	Time 0.285 (0.285)	Data 0.001 (0.009)	
Extract Features: [158/220]	Time 0.281 (0.285)	Data 0.001 (0.009)	
Extract Features: [159/220]	Time 0.278 (0.285)	Data 0.000 (0.009)	
Extract Features: [160/220]	Time 0.274 (0.285)	Data 0.000 (0.009)	
Extract Features: [161/220]	Time 0.278 (0.285)	Data 0.000 (0.009)	
Extract Features: [162/220]	Time 0.278 (0.285)	Data 0.000 (0.009)	
Extract Features: [163/220]	Time 0.272 (0.285)	Data 0.000 (0.009)	
Extract Features: [164/220]	Time 0.279 (0.284)	Data 0.000 (0.009)	
Extract Features: [165/220]	Time 0.280 (0.284)	Data 0.000 (0.009)	
Extract Features: [166/220]	Time 0.281 (0.284)	Data 0.001 (0.009)	
Extract Features: [167/220]	Time 0.281 (0.284)	Data 0.001 (0.008)	
Extract Features: [168/220]	Time 0.278 (0.284)	Data 0.000 (0.008)	
Extract Features: [169/220]	Time 0.275 (0.284)	Data 0.001 (0.008)	
Extract Features: [170/220]	Time 0.283 (0.284)	Data 0.000 (0.008)	
Extract Features: [171/220]	Time 0.290 (0.284)	Data 0.016 (0.008)	
Extract Features: [172/220]	Time 0.273 (0.284)	Data 0.000 (0.008)	
Extract Features: [173/220]	Time 0.280 (0.284)	Data 0.000 (0.008)	
Extract Features: [174/220]	Time 0.280 (0.284)	Data 0.000 (0.008)	
Extract Features: [175/220]	Time 0.269 (0.284)	Data 0.001 (0.008)	
Extract Features: [176/220]	Time 0.284 (0.284)	Data 0.002 (0.008)	
Extract Features: [177/220]	Time 0.277 (0.284)	Data 0.000 (0.008)	
Extract Features: [178/220]	Time 0.281 (0.284)	Data 0.000 (0.008)	
Extract Features: [179/220]	Time 0.308 (0.284)	Data 0.017 (0.008)	
Extract Features: [180/220]	Time 0.266 (0.284)	Data 0.000 (0.008)	
Extract Features: [181/220]	Time 0.273 (0.284)	Data 0.000 (0.008)	
Extract Features: [182/220]	Time 0.276 (0.284)	Data 0.000 (0.008)	
Extract Features: [183/220]	Time 0.269 (0.284)	Data 0.000 (0.008)	
Extract Features: [184/220]	Time 0.277 (0.284)	Data 0.009 (0.008)	
Extract Features: [185/220]	Time 0.284 (0.284)	Data 0.000 (0.008)	
Extract Features: [186/220]	Time 0.279 (0.284)	Data 0.000 (0.008)	
Extract Features: [187/220]	Time 0.279 (0.284)	Data 0.000 (0.008)	
Extract Features: [188/220]	Time 0.279 (0.284)	Data 0.000 (0.008)	
Extract Features: [189/220]	Time 0.268 (0.284)	Data 0.001 (0.008)	
Extract Features: [190/220]	Time 0.304 (0.284)	Data 0.012 (0.008)	
Extract Features: [191/220]	Time 0.273 (0.284)	Data 0.001 (0.008)	
Extract Features: [192/220]	Time 0.271 (0.284)	Data 0.006 (0.008)	
Extract Features: [193/220]	Time 0.294 (0.284)	Data 0.000 (0.008)	
Extract Features: [194/220]	Time 0.276 (0.284)	Data 0.000 (0.008)	
Extract Features: [195/220]	Time 0.277 (0.284)	Data 0.001 (0.008)	
Extract Features: [196/220]	Time 0.283 (0.284)	Data 0.000 (0.008)	
Extract Features: [197/220]	Time 0.286 (0.284)	Data 0.000 (0.008)	
Extract Features: [198/220]	Time 0.279 (0.284)	Data 0.000 (0.008)	
Extract Features: [199/220]	Time 0.271 (0.284)	Data 0.001 (0.007)	
Extract Features: [200/220]	Time 0.287 (0.284)	Data 0.010 (0.007)	
Extract Features: [201/220]	Time 0.275 (0.284)	Data 0.001 (0.007)	
Extract Features: [202/220]	Time 0.273 (0.284)	Data 0.000 (0.007)	
Extract Features: [203/220]	Time 0.284 (0.284)	Data 0.000 (0.007)	
Extract Features: [204/220]	Time 0.269 (0.283)	Data 0.000 (0.007)	
Extract Features: [205/220]	Time 0.271 (0.283)	Data 0.000 (0.007)	
Extract Features: [206/220]	Time 0.266 (0.283)	Data 0.000 (0.007)	
Extract Features: [207/220]	Time 0.267 (0.283)	Data 0.000 (0.007)	
Extract Features: [208/220]	Time 0.266 (0.283)	Data 0.000 (0.007)	
Extract Features: [209/220]	Time 0.265 (0.283)	Data 0.000 (0.007)	
Extract Features: [210/220]	Time 0.267 (0.283)	Data 0.000 (0.007)	
Extract Features: [211/220]	Time 0.267 (0.283)	Data 0.000 (0.007)	
Extract Features: [212/220]	Time 0.266 (0.283)	Data 0.000 (0.007)	
Extract Features: [213/220]	Time 0.268 (0.283)	Data 0.000 (0.007)	
Extract Features: [214/220]	Time 0.266 (0.283)	Data 0.000 (0.007)	
Extract Features: [215/220]	Time 0.268 (0.283)	Data 0.000 (0.007)	
Extract Features: [216/220]	Time 0.267 (0.283)	Data 0.000 (0.007)	
Extract Features: [217/220]	Time 0.267 (0.282)	Data 0.000 (0.007)	
Extract Features: [218/220]	Time 0.268 (0.282)	Data 0.000 (0.007)	
Extract Features: [219/220]	Time 0.265 (0.282)	Data 0.000 (0.007)	
Extract Features: [220/220]	Time 1.221 (0.287)	Data 0.000 (0.007)	
Mean AP: 25.4%
CMC Scores
  top-1          41.3%
  top-5          57.9%
  top-10         63.9%
  top-20         69.7%
Market dataset loaded
  subset   | # ids | # images
  ---------------------------
  train    |   502 |     3291
  query    |   450 |     2057
  gallery  |   934 |    30404
  camstyle  |     0 |        0
=> Loaded checkpoint 'logs/market-ide/checkpoint.pth.tar'
=> Start epoch 50 
Test:
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:49: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(self.feat.weight, mode='fan_out')
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:50: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:51: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.weight, 1)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:52: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(self.classifier.weight, std=0.001)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:61: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.classifier.bias, 0)
Extract Features: [1/17]	Time 3.611 (3.611)	Data 1.727 (1.727)	
Extract Features: [2/17]	Time 0.265 (1.938)	Data 0.000 (0.863)	
Extract Features: [3/17]	Time 0.266 (1.381)	Data 0.000 (0.576)	
Extract Features: [4/17]	Time 0.263 (1.101)	Data 0.000 (0.432)	
Extract Features: [5/17]	Time 0.266 (0.934)	Data 0.000 (0.345)	
Extract Features: [6/17]	Time 0.264 (0.823)	Data 0.000 (0.288)	
Extract Features: [7/17]	Time 0.265 (0.743)	Data 0.000 (0.247)	
Extract Features: [8/17]	Time 0.262 (0.683)	Data 0.000 (0.216)	
Extract Features: [9/17]	Time 0.265 (0.636)	Data 0.000 (0.192)	
Extract Features: [10/17]	Time 0.265 (0.599)	Data 0.000 (0.173)	
Extract Features: [11/17]	Time 0.264 (0.569)	Data 0.000 (0.157)	
Extract Features: [12/17]	Time 0.265 (0.544)	Data 0.000 (0.144)	
Extract Features: [13/17]	Time 0.262 (0.522)	Data 0.000 (0.133)	
Extract Features: [14/17]	Time 0.266 (0.504)	Data 0.000 (0.123)	
Extract Features: [15/17]	Time 0.266 (0.488)	Data 0.000 (0.115)	
Extract Features: [16/17]	Time 0.263 (0.474)	Data 0.000 (0.108)	
Extract Features: [17/17]	Time 0.544 (0.478)	Data 0.000 (0.102)	
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs = Variable(inputs, volatile=True)
Extract Features: [1/238]	Time 1.159 (1.159)	Data 0.892 (0.892)	
Extract Features: [2/238]	Time 0.264 (0.711)	Data 0.000 (0.446)	
Extract Features: [3/238]	Time 0.281 (0.568)	Data 0.010 (0.301)	
Extract Features: [4/238]	Time 0.288 (0.498)	Data 0.010 (0.228)	
Extract Features: [5/238]	Time 0.303 (0.459)	Data 0.014 (0.185)	
Extract Features: [6/238]	Time 0.286 (0.430)	Data 0.001 (0.155)	
Extract Features: [7/238]	Time 0.302 (0.412)	Data 0.012 (0.134)	
Extract Features: [8/238]	Time 0.285 (0.396)	Data 0.001 (0.118)	
Extract Features: [9/238]	Time 0.280 (0.383)	Data 0.005 (0.105)	
Extract Features: [10/238]	Time 0.279 (0.373)	Data 0.001 (0.095)	
Extract Features: [11/238]	Time 0.281 (0.364)	Data 0.001 (0.086)	
Extract Features: [12/238]	Time 0.278 (0.357)	Data 0.002 (0.079)	
Extract Features: [13/238]	Time 0.280 (0.351)	Data 0.001 (0.073)	
Extract Features: [14/238]	Time 0.274 (0.346)	Data 0.001 (0.068)	
Extract Features: [15/238]	Time 0.266 (0.340)	Data 0.001 (0.063)	
Extract Features: [16/238]	Time 0.281 (0.337)	Data 0.003 (0.060)	
Extract Features: [17/238]	Time 0.279 (0.333)	Data 0.001 (0.056)	
Extract Features: [18/238]	Time 0.279 (0.330)	Data 0.000 (0.053)	
Extract Features: [19/238]	Time 0.280 (0.328)	Data 0.000 (0.050)	
Extract Features: [20/238]	Time 0.274 (0.325)	Data 0.000 (0.048)	
Extract Features: [21/238]	Time 0.282 (0.323)	Data 0.001 (0.046)	
Extract Features: [22/238]	Time 0.273 (0.321)	Data 0.001 (0.043)	
Extract Features: [23/238]	Time 0.275 (0.319)	Data 0.000 (0.042)	
Extract Features: [24/238]	Time 0.280 (0.317)	Data 0.001 (0.040)	
Extract Features: [25/238]	Time 0.278 (0.315)	Data 0.001 (0.038)	
Extract Features: [26/238]	Time 0.270 (0.314)	Data 0.000 (0.037)	
Extract Features: [27/238]	Time 0.273 (0.312)	Data 0.000 (0.036)	
Extract Features: [28/238]	Time 0.274 (0.311)	Data 0.001 (0.034)	
Extract Features: [29/238]	Time 0.269 (0.309)	Data 0.000 (0.033)	
Extract Features: [30/238]	Time 0.276 (0.308)	Data 0.000 (0.032)	
Extract Features: [31/238]	Time 0.285 (0.307)	Data 0.008 (0.031)	
Extract Features: [32/238]	Time 0.284 (0.307)	Data 0.001 (0.030)	
Extract Features: [33/238]	Time 0.281 (0.306)	Data 0.005 (0.030)	
Extract Features: [34/238]	Time 0.281 (0.305)	Data 0.002 (0.029)	
Extract Features: [35/238]	Time 0.279 (0.304)	Data 0.004 (0.028)	
Extract Features: [36/238]	Time 0.274 (0.304)	Data 0.002 (0.027)	
Extract Features: [37/238]	Time 0.273 (0.303)	Data 0.000 (0.027)	
Extract Features: [38/238]	Time 0.271 (0.302)	Data 0.000 (0.026)	
Extract Features: [39/238]	Time 0.280 (0.301)	Data 0.001 (0.025)	
Extract Features: [40/238]	Time 0.281 (0.301)	Data 0.001 (0.025)	
Extract Features: [41/238]	Time 0.281 (0.300)	Data 0.001 (0.024)	
Extract Features: [42/238]	Time 0.286 (0.300)	Data 0.006 (0.024)	
Extract Features: [43/238]	Time 0.281 (0.300)	Data 0.000 (0.023)	
Extract Features: [44/238]	Time 0.284 (0.299)	Data 0.000 (0.023)	
Extract Features: [45/238]	Time 0.273 (0.299)	Data 0.000 (0.022)	
Extract Features: [46/238]	Time 0.271 (0.298)	Data 0.000 (0.022)	
Extract Features: [47/238]	Time 0.275 (0.298)	Data 0.000 (0.021)	
Extract Features: [48/238]	Time 0.280 (0.297)	Data 0.002 (0.021)	
Extract Features: [49/238]	Time 0.279 (0.297)	Data 0.000 (0.020)	
Extract Features: [50/238]	Time 0.281 (0.297)	Data 0.007 (0.020)	
Extract Features: [51/238]	Time 0.281 (0.296)	Data 0.000 (0.020)	
Extract Features: [52/238]	Time 0.278 (0.296)	Data 0.001 (0.019)	
Extract Features: [53/238]	Time 0.280 (0.296)	Data 0.000 (0.019)	
Extract Features: [54/238]	Time 0.298 (0.296)	Data 0.006 (0.019)	
Extract Features: [55/238]	Time 0.282 (0.295)	Data 0.001 (0.018)	
Extract Features: [56/238]	Time 0.279 (0.295)	Data 0.001 (0.018)	
Extract Features: [57/238]	Time 0.280 (0.295)	Data 0.001 (0.018)	
Extract Features: [58/238]	Time 0.293 (0.295)	Data 0.019 (0.018)	
Extract Features: [59/238]	Time 0.272 (0.294)	Data 0.000 (0.017)	
Extract Features: [60/238]	Time 0.272 (0.294)	Data 0.000 (0.017)	
Extract Features: [61/238]	Time 0.299 (0.294)	Data 0.017 (0.017)	
Extract Features: [62/238]	Time 0.275 (0.294)	Data 0.000 (0.017)	
Extract Features: [63/238]	Time 0.279 (0.294)	Data 0.001 (0.017)	
Extract Features: [64/238]	Time 0.281 (0.293)	Data 0.001 (0.016)	
Extract Features: [65/238]	Time 0.279 (0.293)	Data 0.001 (0.016)	
Extract Features: [66/238]	Time 0.280 (0.293)	Data 0.001 (0.016)	
Extract Features: [67/238]	Time 0.276 (0.293)	Data 0.001 (0.016)	
Extract Features: [68/238]	Time 0.276 (0.292)	Data 0.000 (0.016)	
Extract Features: [69/238]	Time 0.270 (0.292)	Data 0.000 (0.015)	
Extract Features: [70/238]	Time 0.278 (0.292)	Data 0.000 (0.015)	
Extract Features: [71/238]	Time 0.281 (0.292)	Data 0.000 (0.015)	
Extract Features: [72/238]	Time 0.281 (0.292)	Data 0.001 (0.015)	
Extract Features: [73/238]	Time 0.280 (0.291)	Data 0.001 (0.014)	
Extract Features: [74/238]	Time 0.270 (0.291)	Data 0.003 (0.014)	
Extract Features: [75/238]	Time 0.281 (0.291)	Data 0.005 (0.014)	
Extract Features: [76/238]	Time 0.278 (0.291)	Data 0.000 (0.014)	
Extract Features: [77/238]	Time 0.273 (0.291)	Data 0.001 (0.014)	
Extract Features: [78/238]	Time 0.275 (0.290)	Data 0.000 (0.014)	
Extract Features: [79/238]	Time 0.274 (0.290)	Data 0.000 (0.013)	
Extract Features: [80/238]	Time 0.267 (0.290)	Data 0.000 (0.013)	
Extract Features: [81/238]	Time 0.283 (0.290)	Data 0.002 (0.013)	
Extract Features: [82/238]	Time 0.279 (0.290)	Data 0.000 (0.013)	
Extract Features: [83/238]	Time 0.280 (0.290)	Data 0.003 (0.013)	
Extract Features: [84/238]	Time 0.280 (0.289)	Data 0.000 (0.013)	
Extract Features: [85/238]	Time 0.279 (0.289)	Data 0.000 (0.013)	
Extract Features: [86/238]	Time 0.283 (0.289)	Data 0.008 (0.013)	
Extract Features: [87/238]	Time 0.285 (0.289)	Data 0.000 (0.012)	
Extract Features: [88/238]	Time 0.278 (0.289)	Data 0.000 (0.012)	
Extract Features: [89/238]	Time 0.275 (0.289)	Data 0.000 (0.012)	
Extract Features: [90/238]	Time 0.279 (0.289)	Data 0.000 (0.012)	
Extract Features: [91/238]	Time 0.280 (0.289)	Data 0.000 (0.012)	
Extract Features: [92/238]	Time 0.280 (0.289)	Data 0.000 (0.012)	
Extract Features: [93/238]	Time 0.277 (0.289)	Data 0.003 (0.012)	
Extract Features: [94/238]	Time 0.279 (0.288)	Data 0.000 (0.012)	
Extract Features: [95/238]	Time 0.282 (0.288)	Data 0.000 (0.011)	
Extract Features: [96/238]	Time 0.282 (0.288)	Data 0.001 (0.011)	
Extract Features: [97/238]	Time 0.280 (0.288)	Data 0.001 (0.011)	
Extract Features: [98/238]	Time 0.274 (0.288)	Data 0.000 (0.011)	
Extract Features: [99/238]	Time 0.276 (0.288)	Data 0.000 (0.011)	
Extract Features: [100/238]	Time 0.273 (0.288)	Data 0.000 (0.011)	
Extract Features: [101/238]	Time 0.277 (0.288)	Data 0.000 (0.011)	
Extract Features: [102/238]	Time 0.289 (0.288)	Data 0.003 (0.011)	
Extract Features: [103/238]	Time 0.281 (0.288)	Data 0.001 (0.011)	
Extract Features: [104/238]	Time 0.279 (0.288)	Data 0.000 (0.011)	
Extract Features: [105/238]	Time 0.281 (0.288)	Data 0.001 (0.010)	
Extract Features: [106/238]	Time 0.280 (0.287)	Data 0.000 (0.010)	
Extract Features: [107/238]	Time 0.277 (0.287)	Data 0.001 (0.010)	
Extract Features: [108/238]	Time 0.281 (0.287)	Data 0.000 (0.010)	
Extract Features: [109/238]	Time 0.274 (0.287)	Data 0.001 (0.010)	
Extract Features: [110/238]	Time 0.271 (0.287)	Data 0.001 (0.010)	
Extract Features: [111/238]	Time 0.287 (0.287)	Data 0.001 (0.010)	
Extract Features: [112/238]	Time 0.273 (0.287)	Data 0.000 (0.010)	
Extract Features: [113/238]	Time 0.283 (0.287)	Data 0.000 (0.010)	
Extract Features: [114/238]	Time 0.281 (0.287)	Data 0.001 (0.010)	
Extract Features: [115/238]	Time 0.279 (0.287)	Data 0.000 (0.010)	
Extract Features: [116/238]	Time 0.275 (0.287)	Data 0.000 (0.009)	
Extract Features: [117/238]	Time 0.279 (0.287)	Data 0.000 (0.009)	
Extract Features: [118/238]	Time 0.279 (0.286)	Data 0.001 (0.009)	
Extract Features: [119/238]	Time 0.280 (0.286)	Data 0.000 (0.009)	
Extract Features: [120/238]	Time 0.281 (0.286)	Data 0.000 (0.009)	
Extract Features: [121/238]	Time 0.280 (0.286)	Data 0.000 (0.009)	
Extract Features: [122/238]	Time 0.280 (0.286)	Data 0.001 (0.009)	
Extract Features: [123/238]	Time 0.280 (0.286)	Data 0.000 (0.009)	
Extract Features: [124/238]	Time 0.278 (0.286)	Data 0.000 (0.009)	/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:66: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  dist.addmm_(1, -2, x, y.t())

Extract Features: [125/238]	Time 0.275 (0.286)	Data 0.001 (0.009)	
Extract Features: [126/238]	Time 0.276 (0.286)	Data 0.000 (0.009)	
Extract Features: [127/238]	Time 0.280 (0.286)	Data 0.000 (0.009)	
Extract Features: [128/238]	Time 0.271 (0.286)	Data 0.003 (0.009)	
Extract Features: [129/238]	Time 0.288 (0.286)	Data 0.002 (0.009)	
Extract Features: [130/238]	Time 0.300 (0.286)	Data 0.020 (0.009)	
Extract Features: [131/238]	Time 0.282 (0.286)	Data 0.001 (0.009)	
Extract Features: [132/238]	Time 0.271 (0.286)	Data 0.000 (0.009)	
Extract Features: [133/238]	Time 0.270 (0.286)	Data 0.000 (0.008)	
Extract Features: [134/238]	Time 0.278 (0.286)	Data 0.000 (0.008)	
Extract Features: [135/238]	Time 0.282 (0.286)	Data 0.001 (0.008)	
Extract Features: [136/238]	Time 0.279 (0.286)	Data 0.005 (0.008)	
Extract Features: [137/238]	Time 0.285 (0.286)	Data 0.000 (0.008)	
Extract Features: [138/238]	Time 0.276 (0.286)	Data 0.000 (0.008)	
Extract Features: [139/238]	Time 0.271 (0.285)	Data 0.000 (0.008)	
Extract Features: [140/238]	Time 0.273 (0.285)	Data 0.000 (0.008)	
Extract Features: [141/238]	Time 0.273 (0.285)	Data 0.000 (0.008)	
Extract Features: [142/238]	Time 0.270 (0.285)	Data 0.000 (0.008)	
Extract Features: [143/238]	Time 0.272 (0.285)	Data 0.000 (0.008)	
Extract Features: [144/238]	Time 0.280 (0.285)	Data 0.000 (0.008)	
Extract Features: [145/238]	Time 0.279 (0.285)	Data 0.000 (0.008)	
Extract Features: [146/238]	Time 0.277 (0.285)	Data 0.003 (0.008)	
Extract Features: [147/238]	Time 0.276 (0.285)	Data 0.000 (0.008)	
Extract Features: [148/238]	Time 0.278 (0.285)	Data 0.000 (0.008)	
Extract Features: [149/238]	Time 0.270 (0.285)	Data 0.000 (0.008)	
Extract Features: [150/238]	Time 0.271 (0.285)	Data 0.001 (0.008)	
Extract Features: [151/238]	Time 0.280 (0.285)	Data 0.000 (0.008)	
Extract Features: [152/238]	Time 0.279 (0.285)	Data 0.000 (0.008)	
Extract Features: [153/238]	Time 0.275 (0.284)	Data 0.003 (0.007)	
Extract Features: [154/238]	Time 0.275 (0.284)	Data 0.000 (0.007)	
Extract Features: [155/238]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [156/238]	Time 0.279 (0.284)	Data 0.001 (0.007)	
Extract Features: [157/238]	Time 0.281 (0.284)	Data 0.000 (0.007)	
Extract Features: [158/238]	Time 0.319 (0.285)	Data 0.021 (0.007)	
Extract Features: [159/238]	Time 0.268 (0.284)	Data 0.000 (0.007)	
Extract Features: [160/238]	Time 0.281 (0.284)	Data 0.000 (0.007)	
Extract Features: [161/238]	Time 0.273 (0.284)	Data 0.000 (0.007)	
Extract Features: [162/238]	Time 0.270 (0.284)	Data 0.000 (0.007)	
Extract Features: [163/238]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [164/238]	Time 0.280 (0.284)	Data 0.000 (0.007)	
Extract Features: [165/238]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [166/238]	Time 0.274 (0.284)	Data 0.000 (0.007)	
Extract Features: [167/238]	Time 0.275 (0.284)	Data 0.000 (0.007)	
Extract Features: [168/238]	Time 0.273 (0.284)	Data 0.000 (0.007)	
Extract Features: [169/238]	Time 0.282 (0.284)	Data 0.000 (0.007)	
Extract Features: [170/238]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [171/238]	Time 0.284 (0.284)	Data 0.000 (0.007)	
Extract Features: [172/238]	Time 0.268 (0.284)	Data 0.000 (0.007)	
Extract Features: [173/238]	Time 0.284 (0.284)	Data 0.000 (0.007)	
Extract Features: [174/238]	Time 0.275 (0.284)	Data 0.000 (0.007)	
Extract Features: [175/238]	Time 0.273 (0.284)	Data 0.000 (0.007)	
Extract Features: [176/238]	Time 0.279 (0.284)	Data 0.000 (0.007)	
Extract Features: [177/238]	Time 0.281 (0.284)	Data 0.000 (0.007)	
Extract Features: [178/238]	Time 0.285 (0.284)	Data 0.017 (0.007)	
Extract Features: [179/238]	Time 0.269 (0.284)	Data 0.000 (0.007)	
Extract Features: [180/238]	Time 0.277 (0.284)	Data 0.000 (0.007)	
Extract Features: [181/238]	Time 0.286 (0.284)	Data 0.003 (0.007)	
Extract Features: [182/238]	Time 0.277 (0.284)	Data 0.000 (0.007)	
Extract Features: [183/238]	Time 0.271 (0.284)	Data 0.000 (0.007)	
Extract Features: [184/238]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [185/238]	Time 0.272 (0.283)	Data 0.000 (0.006)	
Extract Features: [186/238]	Time 0.276 (0.283)	Data 0.000 (0.006)	
Extract Features: [187/238]	Time 0.271 (0.283)	Data 0.000 (0.006)	
Extract Features: [188/238]	Time 0.271 (0.283)	Data 0.000 (0.006)	
Extract Features: [189/238]	Time 0.274 (0.283)	Data 0.000 (0.006)	
Extract Features: [190/238]	Time 0.266 (0.283)	Data 0.000 (0.006)	
Extract Features: [191/238]	Time 0.282 (0.283)	Data 0.000 (0.006)	
Extract Features: [192/238]	Time 0.281 (0.283)	Data 0.000 (0.006)	
Extract Features: [193/238]	Time 0.274 (0.283)	Data 0.000 (0.006)	
Extract Features: [194/238]	Time 0.268 (0.283)	Data 0.000 (0.006)	
Extract Features: [195/238]	Time 0.289 (0.283)	Data 0.001 (0.006)	
Extract Features: [196/238]	Time 0.278 (0.283)	Data 0.000 (0.006)	
Extract Features: [197/238]	Time 0.276 (0.283)	Data 0.000 (0.006)	
Extract Features: [198/238]	Time 0.289 (0.283)	Data 0.001 (0.006)	
Extract Features: [199/238]	Time 0.281 (0.283)	Data 0.001 (0.006)	
Extract Features: [200/238]	Time 0.281 (0.283)	Data 0.001 (0.006)	
Extract Features: [201/238]	Time 0.277 (0.283)	Data 0.002 (0.006)	
Extract Features: [202/238]	Time 0.281 (0.283)	Data 0.000 (0.006)	
Extract Features: [203/238]	Time 0.271 (0.283)	Data 0.004 (0.006)	
Extract Features: [204/238]	Time 0.280 (0.283)	Data 0.001 (0.006)	
Extract Features: [205/238]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [206/238]	Time 0.282 (0.283)	Data 0.002 (0.006)	
Extract Features: [207/238]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [208/238]	Time 0.275 (0.283)	Data 0.000 (0.006)	
Extract Features: [209/238]	Time 0.275 (0.283)	Data 0.000 (0.006)	
Extract Features: [210/238]	Time 0.268 (0.283)	Data 0.000 (0.006)	
Extract Features: [211/238]	Time 0.291 (0.283)	Data 0.000 (0.006)	
Extract Features: [212/238]	Time 0.282 (0.283)	Data 0.000 (0.006)	
Extract Features: [213/238]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [214/238]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [215/238]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [216/238]	Time 0.279 (0.283)	Data 0.000 (0.006)	
Extract Features: [217/238]	Time 0.279 (0.283)	Data 0.005 (0.006)	
Extract Features: [218/238]	Time 0.277 (0.283)	Data 0.000 (0.006)	
Extract Features: [219/238]	Time 0.282 (0.283)	Data 0.003 (0.006)	
Extract Features: [220/238]	Time 0.283 (0.283)	Data 0.000 (0.006)	
Extract Features: [221/238]	Time 0.280 (0.283)	Data 0.000 (0.006)	
Extract Features: [222/238]	Time 0.274 (0.283)	Data 0.000 (0.006)	
Extract Features: [223/238]	Time 0.273 (0.282)	Data 0.000 (0.005)	
Extract Features: [224/238]	Time 0.269 (0.282)	Data 0.000 (0.005)	
Extract Features: [225/238]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [226/238]	Time 0.268 (0.282)	Data 0.000 (0.005)	
Extract Features: [227/238]	Time 0.269 (0.282)	Data 0.000 (0.005)	
Extract Features: [228/238]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [229/238]	Time 0.268 (0.282)	Data 0.000 (0.005)	
Extract Features: [230/238]	Time 0.266 (0.282)	Data 0.000 (0.005)	
Extract Features: [231/238]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [232/238]	Time 0.268 (0.282)	Data 0.000 (0.005)	
Extract Features: [233/238]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [234/238]	Time 0.270 (0.282)	Data 0.000 (0.005)	
Extract Features: [235/238]	Time 0.265 (0.282)	Data 0.000 (0.005)	
Extract Features: [236/238]	Time 0.268 (0.282)	Data 0.000 (0.005)	
Extract Features: [237/238]	Time 0.267 (0.282)	Data 0.000 (0.005)	
Extract Features: [238/238]	Time 1.351 (0.286)	Data 0.000 (0.005)	
Mean AP: 23.9%
CMC Scores
  top-1          38.9%
  top-5          58.1%
  top-10         63.6%
  top-20         69.5%
Market dataset loaded
  subset   | # ids | # images
  ---------------------------
  train    |   502 |     3291
  query    |   450 |     2057
  gallery  |   931 |    23540
  camstyle  |     0 |        0
=> Loaded checkpoint 'logs/market-ide/checkpoint.pth.tar'
=> Start epoch 50 
Test:
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/server/Workspaces/Python/topics/CamStyle/CycleGAN-for-CamStyle/cGAN/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:49: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(self.feat.weight, mode='fan_out')
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:50: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:51: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.weight, 1)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:52: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.feat_bn.bias, 0)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(self.classifier.weight, std=0.001)
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/models/resnet.py:61: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(self.classifier.bias, 0)
Extract Features: [1/17]	Time 3.398 (3.398)	Data 1.355 (1.355)	
Extract Features: [2/17]	Time 0.272 (1.835)	Data 0.000 (0.678)	
Extract Features: [3/17]	Time 0.268 (1.312)	Data 0.000 (0.452)	
Extract Features: [4/17]	Time 0.268 (1.051)	Data 0.000 (0.339)	
Extract Features: [5/17]	Time 0.267 (0.894)	Data 0.000 (0.271)	
Extract Features: [6/17]	Time 0.270 (0.790)	Data 0.000 (0.226)	
Extract Features: [7/17]	Time 0.268 (0.716)	Data 0.000 (0.194)	
Extract Features: [8/17]	Time 0.269 (0.660)	Data 0.000 (0.170)	
Extract Features: [9/17]	Time 0.270 (0.617)	Data 0.000 (0.151)	
Extract Features: [10/17]	Time 0.268 (0.582)	Data 0.000 (0.136)	
Extract Features: [11/17]	Time 0.271 (0.553)	Data 0.000 (0.123)	
Extract Features: [12/17]	Time 0.268 (0.530)	Data 0.000 (0.113)	
Extract Features: [13/17]	Time 0.268 (0.509)	Data 0.000 (0.104)	
Extract Features: [14/17]	Time 0.269 (0.492)	Data 0.000 (0.097)	
Extract Features: [15/17]	Time 0.268 (0.477)	Data 0.000 (0.091)	
Extract Features: [16/17]	Time 0.270 (0.464)	Data 0.000 (0.085)	
Extract Features: [17/17]	Time 0.535 (0.469)	Data 0.000 (0.080)	
/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs = Variable(inputs, volatile=True)
Extract Features: [1/184]	Time 1.372 (1.372)	Data 1.105 (1.105)	
Extract Features: [2/184]	Time 0.274 (0.823)	Data 0.000 (0.553)	
Extract Features: [3/184]	Time 0.282 (0.643)	Data 0.000 (0.369)	
Extract Features: [4/184]	Time 0.285 (0.553)	Data 0.000 (0.277)	
Extract Features: [5/184]	Time 0.281 (0.499)	Data 0.000 (0.221)	
Extract Features: [6/184]	Time 0.283 (0.463)	Data 0.000 (0.184)	
Extract Features: [7/184]	Time 0.282 (0.437)	Data 0.005 (0.159)	
Extract Features: [8/184]	Time 0.271 (0.416)	Data 0.000 (0.139)	
Extract Features: [9/184]	Time 0.281 (0.401)	Data 0.000 (0.124)	
Extract Features: [10/184]	Time 0.277 (0.389)	Data 0.000 (0.111)	
Extract Features: [11/184]	Time 0.275 (0.378)	Data 0.000 (0.101)	
Extract Features: [12/184]	Time 0.297 (0.372)	Data 0.018 (0.094)	
Extract Features: [13/184]	Time 0.307 (0.367)	Data 0.016 (0.088)	
Extract Features: [14/184]	Time 0.293 (0.361)	Data 0.001 (0.082)	
Extract Features: [15/184]	Time 0.283 (0.356)	Data 0.001 (0.077)	
Extract Features: [16/184]	Time 0.284 (0.352)	Data 0.000 (0.072)	
Extract Features: [17/184]	Time 0.278 (0.347)	Data 0.006 (0.068)	
Extract Features: [18/184]	Time 0.281 (0.344)	Data 0.000 (0.064)	
Extract Features: [19/184]	Time 0.279 (0.340)	Data 0.001 (0.061)	
Extract Features: [20/184]	Time 0.282 (0.337)	Data 0.001 (0.058)	
Extract Features: [21/184]	Time 0.281 (0.335)	Data 0.001 (0.055)	
Extract Features: [22/184]	Time 0.286 (0.332)	Data 0.001 (0.053)	
Extract Features: [23/184]	Time 0.289 (0.331)	Data 0.006 (0.051)	
Extract Features: [24/184]	Time 0.269 (0.328)	Data 0.000 (0.049)	
Extract Features: [25/184]	Time 0.274 (0.326)	Data 0.000 (0.047)	
Extract Features: [26/184]	Time 0.291 (0.325)	Data 0.000 (0.045)	
Extract Features: [27/184]	Time 0.281 (0.323)	Data 0.001 (0.043)	
Extract Features: [28/184]	Time 0.285 (0.322)	Data 0.000 (0.042)	
Extract Features: [29/184]	Time 0.282 (0.320)	Data 0.000 (0.040)	
Extract Features: [30/184]	Time 0.281 (0.319)	Data 0.001 (0.039)	
Extract Features: [31/184]	Time 0.292 (0.318)	Data 0.001 (0.038)	
Extract Features: [32/184]	Time 0.270 (0.317)	Data 0.001 (0.037)	
Extract Features: [33/184]	Time 0.317 (0.317)	Data 0.034 (0.036)	
Extract Features: [34/184]	Time 0.269 (0.315)	Data 0.000 (0.035)	
Extract Features: [35/184]	Time 0.298 (0.315)	Data 0.028 (0.035)	
Extract Features: [36/184]	Time 0.313 (0.315)	Data 0.022 (0.035)	
Extract Features: [37/184]	Time 0.270 (0.313)	Data 0.001 (0.034)	
Extract Features: [38/184]	Time 0.319 (0.314)	Data 0.022 (0.034)	
Extract Features: [39/184]	Time 0.294 (0.313)	Data 0.019 (0.033)	
Extract Features: [40/184]	Time 0.279 (0.312)	Data 0.001 (0.032)	
Extract Features: [41/184]	Time 0.271 (0.311)	Data 0.000 (0.032)	
Extract Features: [42/184]	Time 0.284 (0.311)	Data 0.001 (0.031)	
Extract Features: [43/184]	Time 0.289 (0.310)	Data 0.000 (0.030)	
Extract Features: [44/184]	Time 0.284 (0.309)	Data 0.001 (0.030)	
Extract Features: [45/184]	Time 0.277 (0.309)	Data 0.001 (0.029)	
Extract Features: [46/184]	Time 0.285 (0.308)	Data 0.000 (0.028)	
Extract Features: [47/184]	Time 0.284 (0.308)	Data 0.001 (0.028)	
Extract Features: [48/184]	Time 0.283 (0.307)	Data 0.001 (0.027)	
Extract Features: [49/184]	Time 0.286 (0.307)	Data 0.000 (0.027)	
Extract Features: [50/184]	Time 0.280 (0.306)	Data 0.000 (0.026)	
Extract Features: [51/184]	Time 0.270 (0.305)	Data 0.000 (0.026)	
Extract Features: [52/184]	Time 0.291 (0.305)	Data 0.000 (0.025)	
Extract Features: [53/184]	Time 0.271 (0.305)	Data 0.000 (0.025)	
Extract Features: [54/184]	Time 0.282 (0.304)	Data 0.000 (0.024)	
Extract Features: [55/184]	Time 0.277 (0.304)	Data 0.000 (0.024)	
Extract Features: [56/184]	Time 0.285 (0.303)	Data 0.000 (0.023)	
Extract Features: [57/184]	Time 0.277 (0.303)	Data 0.001 (0.023)	
Extract Features: [58/184]	Time 0.276 (0.302)	Data 0.000 (0.023)	
Extract Features: [59/184]	Time 0.277 (0.302)	Data 0.000 (0.022)	
Extract Features: [60/184]	Time 0.281 (0.302)	Data 0.000 (0.022)	
Extract Features: [61/184]	Time 0.286 (0.301)	Data 0.001 (0.021)	
Extract Features: [62/184]	Time 0.286 (0.301)	Data 0.000 (0.021)	
Extract Features: [63/184]	Time 0.287 (0.301)	Data 0.000 (0.021)	
Extract Features: [64/184]	Time 0.282 (0.301)	Data 0.000 (0.020)	
Extract Features: [65/184]	Time 0.278 (0.300)	Data 0.001 (0.020)	
Extract Features: [66/184]	Time 0.281 (0.300)	Data 0.000 (0.020)	
Extract Features: [67/184]	Time 0.282 (0.300)	Data 0.001 (0.020)	
Extract Features: [68/184]	Time 0.287 (0.300)	Data 0.000 (0.019)	
Extract Features: [69/184]	Time 0.282 (0.299)	Data 0.000 (0.019)	
Extract Features: [70/184]	Time 0.281 (0.299)	Data 0.000 (0.019)	
Extract Features: [71/184]	Time 0.288 (0.299)	Data 0.000 (0.018)	
Extract Features: [72/184]	Time 0.282 (0.299)	Data 0.001 (0.018)	
Extract Features: [73/184]	Time 0.276 (0.298)	Data 0.002 (0.018)	
Extract Features: [74/184]	Time 0.283 (0.298)	Data 0.000 (0.018)	
Extract Features: [75/184]	Time 0.280 (0.298)	Data 0.001 (0.018)	
Extract Features: [76/184]	Time 0.290 (0.298)	Data 0.000 (0.017)	
Extract Features: [77/184]	Time 0.274 (0.297)	Data 0.002 (0.017)	
Extract Features: [78/184]	Time 0.285 (0.297)	Data 0.000 (0.017)	
Extract Features: [79/184]	Time 0.290 (0.297)	Data 0.008 (0.017)	
Extract Features: [80/184]	Time 0.282 (0.297)	Data 0.000 (0.017)	
Extract Features: [81/184]	Time 0.279 (0.297)	Data 0.000 (0.016)	
Extract Features: [82/184]	Time 0.280 (0.297)	Data 0.000 (0.016)	
Extract Features: [83/184]	Time 0.281 (0.296)	Data 0.000 (0.016)	
Extract Features: [84/184]	Time 0.281 (0.296)	Data 0.000 (0.016)	
Extract Features: [85/184]	Time 0.279 (0.296)	Data 0.000 (0.016)	
Extract Features: [86/184]	Time 0.288 (0.296)	Data 0.000 (0.015)	
Extract Features: [87/184]	Time 0.285 (0.296)	Data 0.006 (0.015)	
Extract Features: [88/184]	Time 0.279 (0.296)	Data 0.000 (0.015)	
Extract Features: [89/184]	Time 0.274 (0.295)	Data 0.003 (0.015)	
Extract Features: [90/184]	Time 0.287 (0.295)	Data 0.000 (0.015)	
Extract Features: [91/184]	Time 0.283 (0.295)	Data 0.000 (0.015)	
Extract Features: [92/184]	Time 0.288 (0.295)	Data 0.000 (0.015)	
Extract Features: [93/184]	Time 0.271 (0.295)	Data 0.000 (0.014)	
Extract Features: [94/184]	Time 0.279 (0.295)	Data 0.001 (0.014)	
Extract Features: [95/184]	Time 0.286 (0.294)	Data 0.000 (0.014)	
Extract Features: [96/184]	Time 0.289 (0.294)	Data 0.000 (0.014)	
Extract Features: [97/184]	Time 0.271 (0.294)	Data 0.001 (0.014)	
Extract Features: [98/184]	Time 0.281 (0.294)	Data 0.000 (0.014)	
Extract Features: [99/184]	Time 0.289 (0.294)	Data 0.009 (0.014)	
Extract Features: [100/184]	Time 0.286 (0.294)	Data 0.000 (0.013)	
Extract Features: [101/184]	Time 0.277 (0.294)	Data 0.000 (0.013)	
Extract Features: [102/184]	Time 0.283 (0.294)	Data 0.000 (0.013)	
Extract Features: [103/184]	Time 0.289 (0.294)	Data 0.010 (0.013)	
Extract Features: [104/184]	Time 0.281 (0.293)	Data 0.000 (0.013)	
Extract Features: [105/184]	Time 0.285 (0.293)	Data 0.000 (0.013)	
Extract Features: [106/184]	Time 0.290 (0.293)	Data 0.006 (0.013)	
Extract Features: [107/184]	Time 0.271 (0.293)	Data 0.000 (0.013)	
Extract Features: [108/184]	Time 0.277 (0.293)	Data 0.000 (0.013)	
Extract Features: [109/184]	Time 0.280 (0.293)	Data 0.001 (0.013)	
Extract Features: [110/184]	Time 0.282 (0.293)	Data 0.000 (0.012)	
Extract Features: [111/184]	Time 0.281 (0.293)	Data 0.000 (0.012)	
Extract Features: [112/184]	Time 0.286 (0.293)	Data 0.000 (0.012)	
Extract Features: [113/184]	Time 0.283 (0.293)	Data 0.000 (0.012)	
Extract Features: [114/184]	Time 0.278 (0.292)	Data 0.000 (0.012)	
Extract Features: [115/184]	Time 0.283 (0.292)	Data 0.000 (0.012)	
Extract Features: [116/184]	Time 0.280 (0.292)	Data 0.001 (0.012)	
Extract Features: [117/184]	Time 0.283 (0.292)	Data 0.000 (0.012)	
Extract Features: [118/184]	Time 0.277 (0.292)	Data 0.000 (0.012)	
Extract Features: [119/184]	Time 0.280 (0.292)	Data 0.000 (0.012)	
Extract Features: [120/184]	Time 0.287 (0.292)	Data 0.000 (0.011)	
Extract Features: [121/184]	Time 0.284 (0.292)	Data 0.000 (0.011)	
Extract Features: [122/184]	Time 0.271 (0.292)	Data 0.001 (0.011)	
Extract Features: [123/184]	Time 0.298 (0.292)	Data 0.005 (0.011)	
Extract Features: [124/184]	Time 0.282 (0.292)	Data 0.000 (0.011)	/home/server/Workspaces/Python/topics/re-id-camstyle/reid/evaluators.py:66: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  dist.addmm_(1, -2, x, y.t())

Extract Features: [125/184]	Time 0.280 (0.292)	Data 0.000 (0.011)	
Extract Features: [126/184]	Time 0.287 (0.291)	Data 0.000 (0.011)	
Extract Features: [127/184]	Time 0.274 (0.291)	Data 0.001 (0.011)	
Extract Features: [128/184]	Time 0.279 (0.291)	Data 0.000 (0.011)	
Extract Features: [129/184]	Time 0.283 (0.291)	Data 0.000 (0.011)	
Extract Features: [130/184]	Time 0.283 (0.291)	Data 0.000 (0.011)	
Extract Features: [131/184]	Time 0.289 (0.291)	Data 0.000 (0.011)	
Extract Features: [132/184]	Time 0.278 (0.291)	Data 0.000 (0.010)	
Extract Features: [133/184]	Time 0.284 (0.291)	Data 0.001 (0.010)	
Extract Features: [134/184]	Time 0.286 (0.291)	Data 0.000 (0.010)	
Extract Features: [135/184]	Time 0.282 (0.291)	Data 0.000 (0.010)	
Extract Features: [136/184]	Time 0.278 (0.291)	Data 0.000 (0.010)	
Extract Features: [137/184]	Time 0.286 (0.291)	Data 0.000 (0.010)	
Extract Features: [138/184]	Time 0.280 (0.291)	Data 0.000 (0.010)	
Extract Features: [139/184]	Time 0.287 (0.291)	Data 0.000 (0.010)	
Extract Features: [140/184]	Time 0.276 (0.291)	Data 0.000 (0.010)	
Extract Features: [141/184]	Time 0.301 (0.291)	Data 0.001 (0.010)	
Extract Features: [142/184]	Time 0.285 (0.291)	Data 0.000 (0.010)	
Extract Features: [143/184]	Time 0.290 (0.291)	Data 0.000 (0.010)	
Extract Features: [144/184]	Time 0.280 (0.290)	Data 0.000 (0.010)	
Extract Features: [145/184]	Time 0.280 (0.290)	Data 0.000 (0.010)	
Extract Features: [146/184]	Time 0.277 (0.290)	Data 0.000 (0.010)	
Extract Features: [147/184]	Time 0.282 (0.290)	Data 0.000 (0.009)	
Extract Features: [148/184]	Time 0.278 (0.290)	Data 0.000 (0.009)	
Extract Features: [149/184]	Time 0.282 (0.290)	Data 0.000 (0.009)	
Extract Features: [150/184]	Time 0.286 (0.290)	Data 0.000 (0.009)	
Extract Features: [151/184]	Time 0.283 (0.290)	Data 0.000 (0.009)	
Extract Features: [152/184]	Time 0.282 (0.290)	Data 0.000 (0.009)	
Extract Features: [153/184]	Time 0.272 (0.290)	Data 0.000 (0.009)	
Extract Features: [154/184]	Time 0.287 (0.290)	Data 0.002 (0.009)	
Extract Features: [155/184]	Time 0.286 (0.290)	Data 0.000 (0.009)	
Extract Features: [156/184]	Time 0.279 (0.290)	Data 0.000 (0.009)	
Extract Features: [157/184]	Time 0.274 (0.290)	Data 0.000 (0.009)	
Extract Features: [158/184]	Time 0.276 (0.290)	Data 0.000 (0.009)	
Extract Features: [159/184]	Time 0.276 (0.289)	Data 0.000 (0.009)	
Extract Features: [160/184]	Time 0.273 (0.289)	Data 0.002 (0.009)	
Extract Features: [161/184]	Time 0.279 (0.289)	Data 0.001 (0.009)	
Extract Features: [162/184]	Time 0.286 (0.289)	Data 0.000 (0.009)	
Extract Features: [163/184]	Time 0.275 (0.289)	Data 0.000 (0.009)	
Extract Features: [164/184]	Time 0.277 (0.289)	Data 0.000 (0.009)	
Extract Features: [165/184]	Time 0.288 (0.289)	Data 0.000 (0.008)	
Extract Features: [166/184]	Time 0.277 (0.289)	Data 0.000 (0.008)	
Extract Features: [167/184]	Time 0.282 (0.289)	Data 0.005 (0.008)	
Extract Features: [168/184]	Time 0.282 (0.289)	Data 0.000 (0.008)	
Extract Features: [169/184]	Time 0.280 (0.289)	Data 0.000 (0.008)	
Extract Features: [170/184]	Time 0.272 (0.289)	Data 0.000 (0.008)	
Extract Features: [171/184]	Time 0.275 (0.289)	Data 0.000 (0.008)	
Extract Features: [172/184]	Time 0.270 (0.289)	Data 0.000 (0.008)	
Extract Features: [173/184]	Time 0.271 (0.289)	Data 0.000 (0.008)	
Extract Features: [174/184]	Time 0.273 (0.288)	Data 0.000 (0.008)	
Extract Features: [175/184]	Time 0.272 (0.288)	Data 0.000 (0.008)	
Extract Features: [176/184]	Time 0.272 (0.288)	Data 0.000 (0.008)	
Extract Features: [177/184]	Time 0.271 (0.288)	Data 0.000 (0.008)	
Extract Features: [178/184]	Time 0.271 (0.288)	Data 0.000 (0.008)	
Extract Features: [179/184]	Time 0.274 (0.288)	Data 0.000 (0.008)	
Extract Features: [180/184]	Time 0.272 (0.288)	Data 0.000 (0.008)	
Extract Features: [181/184]	Time 0.271 (0.288)	Data 0.000 (0.008)	
Extract Features: [182/184]	Time 0.273 (0.288)	Data 0.000 (0.008)	
Extract Features: [183/184]	Time 0.271 (0.288)	Data 0.000 (0.008)	
Extract Features: [184/184]	Time 1.930 (0.297)	Data 0.000 (0.008)	
Mean AP: 24.6%
CMC Scores
  top-1          36.5%
  top-5          54.0%
  top-10         60.1%
  top-20         66.1%
